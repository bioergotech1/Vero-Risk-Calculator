{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc55fb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Users\\HP\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 390, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20984\\2153879480.py\", line 2, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pandas\\__init__.py\", line 80, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pandas\\core\\api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\arrow\\__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\arrow\\array.py\", line 53, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\__init__.py\", line 8, in <module>\n",
      "    from pandas.core.ops.array_ops import (\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\", line 56, in <module>\n",
      "    from pandas.core.computation import expressions\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py\", line 21, in <module>\n",
      "    from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\check.py\", line 5, in <module>\n",
      "    ne = import_optional_dependency(\"numexpr\", errors=\"warn\")\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\numexpr\\__init__.py\", line 24, in <module>\n",
      "    from numexpr.interpreter import MAX_THREADS, use_vml, __BLOCK_SIZE1__\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Users\\HP\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 390, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20984\\2153879480.py\", line 2, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pandas\\__init__.py\", line 80, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pandas\\core\\api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\arrow\\__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\arrow\\array.py\", line 67, in <module>\n",
      "    from pandas.core.arrays.masked import BaseMaskedArray\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py\", line 61, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\", line 52, in <module>\n",
      "    bn = import_optional_dependency(\"bottleneck\", errors=\"warn\")\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\bottleneck\\__init__.py\", line 7, in <module>\n",
      "    from .move import (move_argmax, move_argmin, move_max, move_mean, move_median,\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hospitalization shape: (406, 47)\n",
      "Severe ADR shape: (406, 46)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "BASE_DIR = r\"C:\\Users\\HP\\OneDrive\\Desktop\\Phase 1\\Clean Data\"\n",
    "\n",
    "\n",
    "hosp_path  = os.path.join(BASE_DIR, \"hospitalization_model_matrix_imputed_v1.csv\")\n",
    "adr_path   = os.path.join(BASE_DIR, \"severe_adr_model_matrix_imputed_v1.csv\")\n",
    "\n",
    "\n",
    "hosp_df  = pd.read_csv(hosp_path)\n",
    "adr_df   = pd.read_csv(adr_path)\n",
    "\n",
    "\n",
    "print(\"Hospitalization shape:\", hosp_df.shape)\n",
    "print(\"Severe ADR shape:\", adr_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bb6496f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hosp. events:\n",
      "hospitalization_flag\n",
      "0    307\n",
      "1     99\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "Severe ADR events:\n",
      "severe_adr_flag\n",
      "0    209\n",
      "1     52\n",
      "Name: count, dtype: Int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20984\\3614344884.py:12: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  hosp_df[\"hospitalization_flag\"]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Fix values like \"Yes\", \"No\", mixed cases, spaces etc.\n",
    "yes_no_map = {\n",
    "    \"yes\": 1, \"y\": 1, \"1\": 1, 1: 1, True: 1,\n",
    "    \"no\": 0, \"n\": 0, \"0\": 0, 0: 0, False: 0\n",
    "}\n",
    "\n",
    "# --- HOSPITALIZATION FLAG ---\n",
    "hosp_df[\"hospitalization_flag\"] = (\n",
    "    hosp_df[\"hospitalization_flag\"]\n",
    "    .astype(str)\n",
    "    .str.lower()\n",
    "    .str.strip()\n",
    "    .replace(yes_no_map)\n",
    ")\n",
    "\n",
    "# Convert final values to numeric, coerce non-matching to NaN\n",
    "hosp_df[\"hospitalization_flag\"] = pd.to_numeric(\n",
    "    hosp_df[\"hospitalization_flag\"], errors=\"coerce\"\n",
    ").astype(\"Int64\")\n",
    "\n",
    "# Keep only valid rows (0 or 1)\n",
    "hosp_df = hosp_df[hosp_df[\"hospitalization_flag\"].isin([0, 1])]\n",
    "\n",
    "# --- SEVERE ADR FLAG ---\n",
    "adr_model_df = adr_df.copy()\n",
    "adr_model_df[\"severe_adr_flag\"] = (\n",
    "    adr_model_df[\"severe_adr_flag\"]\n",
    "    .astype(str)\n",
    "    .str.lower()\n",
    "    .str.strip()\n",
    "    .replace(yes_no_map)\n",
    ")\n",
    "\n",
    "adr_model_df[\"severe_adr_flag\"] = pd.to_numeric(\n",
    "    adr_model_df[\"severe_adr_flag\"], errors=\"coerce\"\n",
    ").astype(\"Int64\")\n",
    "\n",
    "# Keep only valid 0/1 rows\n",
    "adr_model_df = adr_model_df[adr_model_df[\"severe_adr_flag\"].isin([0, 1])]\n",
    "\n",
    "# Summary\n",
    "print(\"Hosp. events:\")\n",
    "print(hosp_df[\"hospitalization_flag\"].value_counts(dropna=False))\n",
    "\n",
    "print(\"\\nSevere ADR events:\")\n",
    "print(adr_model_df[\"severe_adr_flag\"].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cf6ce69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= HOSPITALIZATION =================\n",
      "ID column        : patient_id\n",
      "Outcome column(s): ['hospitalization_flag']\n",
      "Total predictors : 45\n",
      "\n",
      "01. IPB\n",
      "02. age\n",
      "03. age_group\n",
      "04. alcohol_consumption\n",
      "05. alt_gpt_range\n",
      "06. anemia_comorbidity\n",
      "07. aortic_insufficiency\n",
      "08. ast_got_range\n",
      "09. asthma\n",
      "10. atrial_fibrillation\n",
      "11. bmi_category\n",
      "12. cardiovascular_disorders\n",
      "13. cci_score\n",
      "14. cerebrovascular_disorders\n",
      "15. copd\n",
      "16. creatinine_range\n",
      "17. depressive_syndrome\n",
      "18. diabete_tipo_II\n",
      "19. direct_bilirubin_range\n",
      "20. dyslipidemia\n",
      "21. education_level\n",
      "22. employment_status\n",
      "23. ethnicity\n",
      "24. farmaci_cat_n\n",
      "25. gastroesophageal_reflux_full\n",
      "26. gastrointestinal_disorders\n",
      "27. gender\n",
      "28. genotipo_DPYD_type\n",
      "29. hemoglobin_range\n",
      "30. hypertension\n",
      "31. hypertensive_heart_disease\n",
      "32. ischemic_heart_disease\n",
      "33. molecular_alterations\n",
      "34. mutations_present\n",
      "35. neutrophils_percent_range\n",
      "36. obesity_comorbidity\n",
      "37. platelet_count_range\n",
      "38. psychiatric_disorders\n",
      "39. red_blood_cells_range\n",
      "40. renal_insufficiency\n",
      "41. smoking_status_detail\n",
      "42. total_bilirubin_range\n",
      "43. tumor_type\n",
      "44. valid_hospitalization_count\n",
      "45. white_blood_cells_range\n",
      "\n",
      "Python list ready to use:\n",
      "['IPB', 'age', 'age_group', 'alcohol_consumption', 'alt_gpt_range', 'anemia_comorbidity', 'aortic_insufficiency', 'ast_got_range', 'asthma', 'atrial_fibrillation', 'bmi_category', 'cardiovascular_disorders', 'cci_score', 'cerebrovascular_disorders', 'copd', 'creatinine_range', 'depressive_syndrome', 'diabete_tipo_II', 'direct_bilirubin_range', 'dyslipidemia', 'education_level', 'employment_status', 'ethnicity', 'farmaci_cat_n', 'gastroesophageal_reflux_full', 'gastrointestinal_disorders', 'gender', 'genotipo_DPYD_type', 'hemoglobin_range', 'hypertension', 'hypertensive_heart_disease', 'ischemic_heart_disease', 'molecular_alterations', 'mutations_present', 'neutrophils_percent_range', 'obesity_comorbidity', 'platelet_count_range', 'psychiatric_disorders', 'red_blood_cells_range', 'renal_insufficiency', 'smoking_status_detail', 'total_bilirubin_range', 'tumor_type', 'valid_hospitalization_count', 'white_blood_cells_range'] \n",
      "\n",
      "\n",
      "================= SEVERE ADR =================\n",
      "ID column        : patient_id\n",
      "Outcome column(s): ['severe_adr_flag']\n",
      "Total predictors : 44\n",
      "\n",
      "01. IPB\n",
      "02. age\n",
      "03. age_group\n",
      "04. alcohol_consumption\n",
      "05. alt_gpt_range\n",
      "06. anemia_comorbidity\n",
      "07. aortic_insufficiency\n",
      "08. ast_got_range\n",
      "09. asthma\n",
      "10. atrial_fibrillation\n",
      "11. bmi_category\n",
      "12. cardiovascular_disorders\n",
      "13. cci_score\n",
      "14. cerebrovascular_disorders\n",
      "15. copd\n",
      "16. creatinine_range\n",
      "17. depressive_syndrome\n",
      "18. diabete_tipo_II\n",
      "19. direct_bilirubin_range\n",
      "20. dyslipidemia\n",
      "21. education_level\n",
      "22. employment_status\n",
      "23. ethnicity\n",
      "24. farmaci_cat_n\n",
      "25. gastroesophageal_reflux_full\n",
      "26. gastrointestinal_disorders\n",
      "27. gender\n",
      "28. genotipo_DPYD_type\n",
      "29. hemoglobin_range\n",
      "30. hypertension\n",
      "31. hypertensive_heart_disease\n",
      "32. ischemic_heart_disease\n",
      "33. molecular_alterations\n",
      "34. mutations_present\n",
      "35. neutrophils_percent_range\n",
      "36. obesity_comorbidity\n",
      "37. platelet_count_range\n",
      "38. psychiatric_disorders\n",
      "39. red_blood_cells_range\n",
      "40. renal_insufficiency\n",
      "41. smoking_status_detail\n",
      "42. total_bilirubin_range\n",
      "43. tumor_type\n",
      "44. white_blood_cells_range\n",
      "\n",
      "Python list ready to use:\n",
      "['IPB', 'age', 'age_group', 'alcohol_consumption', 'alt_gpt_range', 'anemia_comorbidity', 'aortic_insufficiency', 'ast_got_range', 'asthma', 'atrial_fibrillation', 'bmi_category', 'cardiovascular_disorders', 'cci_score', 'cerebrovascular_disorders', 'copd', 'creatinine_range', 'depressive_syndrome', 'diabete_tipo_II', 'direct_bilirubin_range', 'dyslipidemia', 'education_level', 'employment_status', 'ethnicity', 'farmaci_cat_n', 'gastroesophageal_reflux_full', 'gastrointestinal_disorders', 'gender', 'genotipo_DPYD_type', 'hemoglobin_range', 'hypertension', 'hypertensive_heart_disease', 'ischemic_heart_disease', 'molecular_alterations', 'mutations_present', 'neutrophils_percent_range', 'obesity_comorbidity', 'platelet_count_range', 'psychiatric_disorders', 'red_blood_cells_range', 'renal_insufficiency', 'smoking_status_detail', 'total_bilirubin_range', 'tumor_type', 'white_blood_cells_range'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "BASE_DIR = r\"C:\\Users\\HP\\OneDrive\\Desktop\\Phase 1\\Clean Data\"\n",
    "\n",
    "\n",
    "hosp_path  = os.path.join(BASE_DIR, \"hospitalization_model_matrix_imputed_v1.csv\")\n",
    "adr_path   = os.path.join(BASE_DIR, \"severe_adr_model_matrix_imputed_v1.csv\")\n",
    "\n",
    "\n",
    "hosp_df  = pd.read_csv(hosp_path)\n",
    "adr_df   = pd.read_csv(adr_path)\n",
    "\n",
    "\n",
    "def inspect_covariates(df, id_col, outcome_cols, dataset_name):\n",
    "\n",
    "    predictors = [\n",
    "        col for col in df.columns\n",
    "        if col not in outcome_cols + [id_col]\n",
    "    ]\n",
    "\n",
    "    predictors_sorted = sorted(predictors)\n",
    "\n",
    "    print(f\"\\n================= {dataset_name.upper()} =================\")\n",
    "    print(f\"ID column        : {id_col}\")\n",
    "    print(f\"Outcome column(s): {outcome_cols}\")\n",
    "    print(f\"Total predictors : {len(predictors_sorted)}\\n\")\n",
    "\n",
    "    # 1. Numbered list\n",
    "    for i, col in enumerate(predictors_sorted, start=1):\n",
    "        print(f\"{i:02d}. {col}\")\n",
    "\n",
    "    # 2. Raw Python list for copy-paste into modeling code\n",
    "    print(\"\\nPython list ready to use:\")\n",
    "    print(predictors_sorted, \"\\n\")\n",
    "\n",
    "    return predictors_sorted\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "hosp_covariates = inspect_covariates(\n",
    "    df=hosp_df,\n",
    "    id_col=\"patient_id\",\n",
    "    outcome_cols=[\"hospitalization_flag\"],\n",
    "    dataset_name=\"Hospitalization\"\n",
    ")\n",
    "\n",
    "adr_covariates = inspect_covariates(\n",
    "    df=adr_df,\n",
    "    id_col=\"patient_id\",\n",
    "    outcome_cols=[\"severe_adr_flag\"],\n",
    "    dataset_name=\"Severe ADR\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5422283f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hospitalization shape: (406, 47)\n",
      "Severe ADR shape: (261, 46)\n",
      "Hosp events: hospitalization_flag\n",
      "No     307\n",
      "Yes     99\n",
      "Name: count, dtype: int64\n",
      "Severe ADR events: severe_adr_flag\n",
      "0    209\n",
      "1     52\n",
      "Name: count, dtype: Int64\n",
      "Missing hospital predictors: []\n",
      "Missing severe ADR predictors: []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score,\n",
    "    classification_report, roc_curve, precision_recall_curve\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Base paths\n",
    "# -------------------------------------------------------------------\n",
    "BASE_DIR = r\"C:\\Users\\HP\\OneDrive\\Desktop\\Phase 2\\Binary Models\"\n",
    "BIN_OUT_DIR = os.path.join(BASE_DIR, \"binary_models\")\n",
    "os.makedirs(BIN_OUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Hospitalization shape:\", hosp_df.shape)\n",
    "print(\"Severe ADR shape:\", adr_model_df.shape)\n",
    "\n",
    "print(\"Hosp events:\", hosp_df[\"hospitalization_flag\"].value_counts())\n",
    "print(\"Severe ADR events:\", adr_model_df[\"severe_adr_flag\"].value_counts())\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Predictors per outcome (FULL lists)\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "# Hospitalization: drop hospitalization_flag and valid_hospitalization_count\n",
    "hosp_predictors = [\n",
    "   # Demographics & socio-economic\n",
    "    \"age_group\",\n",
    "    \"gender\",\n",
    "    \"ethnicity\",\n",
    "    \"education_level\",\n",
    "    \"employment_status\",\n",
    "    \"bmi_category\",\n",
    "    \"smoking_status_detail\",\n",
    "    \"alcohol_consumption\",\n",
    "\n",
    "    # Frailty / vulnerability\n",
    "    \"IPB\",\n",
    "    \"cci_score\",\n",
    "\n",
    "    # Comorbidities\n",
    "    \"anemia_comorbidity\",\n",
    "    \"asthma\",\n",
    "    \"atrial_fibrillation\",\n",
    "    \"copd\",\n",
    "    \"depressive_syndrome\",\n",
    "    \"diabete_tipo_II\",\n",
    "    \"dyslipidemia\",\n",
    "    \"hypertension\",\n",
    "    \"hypertensive_heart_disease\",\n",
    "    \"ischemic_heart_disease\",\n",
    "    \"renal_insufficiency\",\n",
    "    \"obesity_comorbidity\",\n",
    "    \"psychiatric_disorders\",\n",
    "    \"cardiovascular_disorders\",\n",
    "    \"cerebrovascular_disorders\",\n",
    "    \"gastrointestinal_disorders\",\n",
    "    \"gastroesophageal_reflux_full\",\n",
    "    \"aortic_insufficiency\",\n",
    "\n",
    "    # Baseline laboratory ranges\n",
    "    \"alt_gpt_range\",\n",
    "    \"ast_got_range\",\n",
    "    \"creatinine_range\",\n",
    "    \"direct_bilirubin_range\",\n",
    "    \"total_bilirubin_range\",\n",
    "    \"hemoglobin_range\",\n",
    "    \"platelet_count_range\",\n",
    "    \"white_blood_cells_range\",\n",
    "    \"red_blood_cells_range\",\n",
    "    \"neutrophils_percent_range\",\n",
    "\n",
    "    # Oncological baseline characteristics\n",
    "    \"tumor_type\",\n",
    "    \"molecular_alterations\",\n",
    "    \"mutations_present\",\n",
    "    \"genotipo_DPYD_type\"\n",
    "]\n",
    "\n",
    "# Severe ADR (already clean)\n",
    "adr_predictors = [\n",
    "    # Demographics & socio-economic\n",
    "    \"age_group\",\n",
    "    \"gender\",\n",
    "    \"ethnicity\",\n",
    "    \"education_level\",\n",
    "    \"employment_status\",\n",
    "    \"bmi_category\",\n",
    "    \"smoking_status_detail\",\n",
    "    \"alcohol_consumption\",\n",
    "\n",
    "    # Frailty / vulnerability\n",
    "    \"IPB\",\n",
    "    \"cci_score\",\n",
    "\n",
    "    # Comorbidities\n",
    "    \"anemia_comorbidity\",\n",
    "    \"asthma\",\n",
    "    \"atrial_fibrillation\",\n",
    "    \"copd\",\n",
    "    \"depressive_syndrome\",\n",
    "    \"diabete_tipo_II\",\n",
    "    \"dyslipidemia\",\n",
    "    \"hypertension\",\n",
    "    \"hypertensive_heart_disease\",\n",
    "    \"ischemic_heart_disease\",\n",
    "    \"renal_insufficiency\",\n",
    "    \"obesity_comorbidity\",\n",
    "    \"psychiatric_disorders\",\n",
    "    \"cardiovascular_disorders\",\n",
    "    \"cerebrovascular_disorders\",\n",
    "    \"gastrointestinal_disorders\",\n",
    "    \"gastroesophageal_reflux_full\",\n",
    "    \"aortic_insufficiency\",\n",
    "\n",
    "    # Baseline laboratory ranges\n",
    "    \"alt_gpt_range\",\n",
    "    \"ast_got_range\",\n",
    "    \"creatinine_range\",\n",
    "    \"direct_bilirubin_range\",\n",
    "    \"total_bilirubin_range\",\n",
    "    \"hemoglobin_range\",\n",
    "    \"platelet_count_range\",\n",
    "    \"white_blood_cells_range\",\n",
    "    \"red_blood_cells_range\",\n",
    "    \"neutrophils_percent_range\",\n",
    "\n",
    "    # Oncology & genetics\n",
    "    \"tumor_type\",\n",
    "    \"molecular_alterations\",\n",
    "    \"mutations_present\",\n",
    "    \"genotipo_DPYD_type\",\n",
    "\n",
    "    # Baseline treatment exposure (ADR-specific)\n",
    "    \"farmaci_cat_n\"\n",
    "]\n",
    "\n",
    "# Sanity check that all columns exist\n",
    "missing_h = [c for c in hosp_predictors if c not in hosp_df.columns]\n",
    "missing_a = [c for c in adr_predictors if c not in adr_model_df.columns]\n",
    "\n",
    "print(\"Missing hospital predictors:\", missing_h)\n",
    "print(\"Missing severe ADR predictors:\", missing_a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b4084f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20984\\1663681603.py:35: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[outcome_col]\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20984\\1663681603.py:135: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  results_df.to_excel(out_path, index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Univariate screening for Hospitalization complete. Saved to:\n",
      "  C:\\Users\\HP\\OneDrive\\Desktop\\Phase 2\\Binary Models\\univariate_screening_hospitalization.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20984\\1663681603.py:35: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[outcome_col]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Univariate screening for Severe_ADR complete. Saved to:\n",
      "  C:\\Users\\HP\\OneDrive\\Desktop\\Phase 2\\Binary Models\\univariate_screening_severeADR.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20984\\1663681603.py:135: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  results_df.to_excel(out_path, index=False)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Helper: detect binary variable\n",
    "# ---------------------------------------------\n",
    "def is_binary(series):\n",
    "    vals = series.dropna().unique()\n",
    "    return len(vals) == 2\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Core function: univariate screening for 1 binary outcome\n",
    "# ---------------------------------------------\n",
    "def run_univariate_screening_binary(df, outcome_col, feature_list, outcome_label, out_path):\n",
    "    \"\"\"\n",
    "    df           : pandas DataFrame with outcome + predictors\n",
    "    outcome_col  : binary outcome column name (0/1 or yes/no)\n",
    "    feature_list : list of predictors to test\n",
    "    outcome_label: nice label for reporting (e.g. 'Hospitalization')\n",
    "    out_path     : path to save Excel\n",
    "    \"\"\"\n",
    "    data = df.copy()\n",
    "\n",
    "    # --- 1) Standardise outcome to 0/1 ---\n",
    "    yes_no_map = {\n",
    "        \"yes\": 1, \"y\": 1, \"1\": 1, 1: 1, True: 1,\n",
    "        \"no\": 0, \"n\": 0, \"0\": 0, 0: 0, False: 0\n",
    "    }\n",
    "\n",
    "    # lower/strip/map where possible\n",
    "    data[outcome_col] = (\n",
    "        data[outcome_col]\n",
    "        .astype(str)\n",
    "        .str.lower()\n",
    "        .str.strip()\n",
    "        .replace(yes_no_map)\n",
    "    )\n",
    "\n",
    "    # coerce to numeric, non-mappable values -> NaN\n",
    "    data[outcome_col] = pd.to_numeric(data[outcome_col], errors=\"coerce\")\n",
    "\n",
    "    # keep only clean 0/1 rows\n",
    "    data = data[data[outcome_col].isin([0, 1])].copy()\n",
    "    data[outcome_col] = data[outcome_col].astype(int)\n",
    "\n",
    "    # quick check\n",
    "    if data.empty or not is_binary(data[outcome_col]):\n",
    "        print(f\"[{outcome_label}] Outcome column '{outcome_col}' is not usable as binary after cleaning.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for feature in feature_list:\n",
    "        if feature not in data.columns:\n",
    "            continue\n",
    "\n",
    "        sub = data[[feature, outcome_col]].dropna()\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        x = sub[feature]\n",
    "        y = sub[outcome_col]\n",
    "\n",
    "        # Decide type of feature\n",
    "        feat_is_num = np.issubdtype(x.dtype, np.number)\n",
    "\n",
    "        try:\n",
    "            # --- Numeric feature vs binary outcome -> t-test ---\n",
    "            if feat_is_num:\n",
    "                if not is_binary(y):\n",
    "                    continue\n",
    "                # make sure ordering is stable\n",
    "                vals = sorted(y.unique())\n",
    "                groups = [x[y == v] for v in vals]\n",
    "                if len(groups) != 2:\n",
    "                    continue\n",
    "                if len(groups[0]) < 2 or len(groups[1]) < 2:\n",
    "                    continue\n",
    "\n",
    "                t_stat, p = stats.ttest_ind(\n",
    "                    groups[0], groups[1],\n",
    "                    nan_policy=\"omit\",\n",
    "                    equal_var=False\n",
    "                )\n",
    "                test = \"T-test\"\n",
    "\n",
    "            # --- Categorical feature vs binary outcome -> Chi-square ---\n",
    "            else:\n",
    "                if not is_binary(y):\n",
    "                    continue\n",
    "                ctab = pd.crosstab(x, y)\n",
    "                # Need at least 2 levels in feature and 2 in outcome\n",
    "                if ctab.shape[0] < 2 or ctab.shape[1] < 2:\n",
    "                    continue\n",
    "\n",
    "                chi2, p, dof, ex = stats.chi2_contingency(ctab)\n",
    "                test = \"Chi-square\"\n",
    "\n",
    "            results.append({\n",
    "                \"Outcome\": outcome_label,\n",
    "                \"Feature\": feature,\n",
    "                \"Test Used\": test,\n",
    "                \"P-Value\": p\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            # Track failures but mark as Error\n",
    "            results.append({\n",
    "                \"Outcome\": outcome_label,\n",
    "                \"Feature\": feature,\n",
    "                \"Test Used\": \"Error\",\n",
    "                \"P-Value\": np.nan\n",
    "            })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    if not results_df.empty:\n",
    "        # FDR correction within this outcome\n",
    "        mask = results_df[\"P-Value\"].notna()\n",
    "        if mask.any():\n",
    "            _, qvals, _, _ = multipletests(\n",
    "                results_df.loc[mask, \"P-Value\"],\n",
    "                alpha=0.05,\n",
    "                method=\"fdr_bh\"\n",
    "            )\n",
    "            results_df.loc[mask, \"Corrected P-Value\"] = qvals\n",
    "\n",
    "        # Sort for readability\n",
    "        results_df = results_df.sort_values([\"P-Value\"], na_position=\"last\")\n",
    "\n",
    "        # Save\n",
    "        results_df.to_excel(out_path, index=False)\n",
    "        print(f\"Univariate screening for {outcome_label} complete. Saved to:\\n  {out_path}\")\n",
    "    else:\n",
    "        print(f\"No valid univariate comparisons for {outcome_label}.\")\n",
    "\n",
    "    return results_df\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Run for HOSPITALIZATION\n",
    "# ------------------------------------------------\n",
    "hosp_uni_path = os.path.join(\n",
    "    BASE_DIR,\n",
    "    \"univariate_screening_hospitalization.xlsx\"\n",
    ")\n",
    "hosp_uni_results = run_univariate_screening_binary(\n",
    "    df=hosp_df,                          # can still contain \"Yes\"/\"No\"\n",
    "    outcome_col=\"hospitalization_flag\",  # will be cleaned inside\n",
    "    feature_list=hosp_predictors,\n",
    "    outcome_label=\"Hospitalization\",\n",
    "    out_path=hosp_uni_path\n",
    ")\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Run for SEVERE ADR\n",
    "# ------------------------------------------------\n",
    "adr_uni_path = os.path.join(\n",
    "    BASE_DIR,\n",
    "    \"univariate_screening_severeADR.xlsx\"\n",
    ")\n",
    "adr_uni_results = run_univariate_screening_binary(\n",
    "    df=adr_model_df,                     # here values might already be 0/1\n",
    "    outcome_col=\"severe_adr_flag\",\n",
    "    feature_list=adr_predictors,\n",
    "    outcome_label=\"Severe_ADR\",\n",
    "    out_path=adr_uni_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "741dd774",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20984\\2020275133.py:13: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  s = s.replace(yes_no_map)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20984\\2020275133.py:13: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  s = s.replace(yes_no_map)\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------\n",
    "# 0) Clean / harmonize binary outcomes\n",
    "# ------------------------------------------------\n",
    "yes_no_map = {\n",
    "    \"present / yes\": 1, \"present/yes\": 1, \"present\": 1,\n",
    "    \"yes\": 1, \"y\": 1, \"1\": 1, \"true\": 1, True: 1,\n",
    "    \"absent / no\": 0, \"absent/no\": 0, \"absent\": 0,\n",
    "    \"no\": 0, \"n\": 0, \"0\": 0, \"false\": 0, False: 0\n",
    "}\n",
    "\n",
    "def clean_binary(series):\n",
    "    s = series.astype(str).str.strip().str.lower()\n",
    "    s = s.replace(yes_no_map)\n",
    "    s = pd.to_numeric(s, errors=\"coerce\")\n",
    "    # keep only 0/1, drop weird stuff\n",
    "    return s.where(s.isin([0, 1]))\n",
    "\n",
    "# Hospitalization\n",
    "hosp_df = hosp_df.copy()\n",
    "hosp_df[\"hospitalization_flag_clean\"] = clean_binary(hosp_df[\"hospitalization_flag\"])\n",
    "\n",
    "# Severe ADR\n",
    "adr_model_df = adr_model_df.copy()\n",
    "adr_model_df[\"severe_adr_flag_clean\"] = clean_binary(adr_model_df[\"severe_adr_flag\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8170edf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from math import sqrt\n",
    "\n",
    "def is_binary(series):\n",
    "    vals = series.dropna().unique()\n",
    "    return len(vals) == 2\n",
    "\n",
    "def cohens_d(x, y):\n",
    "    x = pd.to_numeric(x, errors=\"coerce\").dropna()\n",
    "    y = pd.to_numeric(y, errors=\"coerce\").dropna()\n",
    "    nx, ny = len(x), len(y)\n",
    "    if nx < 2 or ny < 2:\n",
    "        return np.nan\n",
    "    dof = nx + ny - 2\n",
    "    pooled_std = sqrt(((nx - 1) * x.var(ddof=1) + (ny - 1) * y.var(ddof=1)) / dof) if dof > 0 else np.nan\n",
    "    return (x.mean() - y.mean()) / pooled_std if (pooled_std is not None and pooled_std > 0) else np.nan\n",
    "\n",
    "def cramers_v(chi2, n, r, c):\n",
    "    if n == 0:\n",
    "        return np.nan\n",
    "    denom = n * (min(r - 1, c - 1))\n",
    "    if denom <= 0:\n",
    "        return np.nan\n",
    "    return sqrt(chi2 / denom)\n",
    "\n",
    "def run_univariate_with_effects(df, outcome_col, feature_list, outcome_label, save_path):\n",
    "    data = df.copy()\n",
    "    # Ensure binary 0/1 (nullable integer)\n",
    "    data[outcome_col] = pd.to_numeric(data[outcome_col], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for feature in feature_list:\n",
    "        if feature not in data.columns:\n",
    "            continue\n",
    "\n",
    "        sub = data[[feature, outcome_col]].dropna()\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        x = sub[feature]\n",
    "        y = sub[outcome_col]\n",
    "\n",
    "        # Only sensible if outcome is binary\n",
    "        if not is_binary(y):\n",
    "            continue\n",
    "\n",
    "        feat_is_num = np.issubdtype(x.dtype, np.number)\n",
    "\n",
    "        try:\n",
    "            if feat_is_num:\n",
    "                groups = [x[y == val] for val in y.unique()]\n",
    "                if len(groups) != 2:\n",
    "                    continue\n",
    "                if len(groups[0]) < 2 or len(groups[1]) < 2:\n",
    "                    continue\n",
    "\n",
    "                t_stat, p = stats.ttest_ind(\n",
    "                    groups[0], groups[1],\n",
    "                    nan_policy=\"omit\",\n",
    "                    equal_var=False\n",
    "                )\n",
    "                test = \"T-test\"\n",
    "                effect_size = cohens_d(groups[0], groups[1])\n",
    "\n",
    "            else:\n",
    "                ctab = pd.crosstab(x, y)\n",
    "                if ctab.shape[0] < 2 or ctab.shape[1] < 2:\n",
    "                    continue\n",
    "\n",
    "                chi2, p, dof, ex = stats.chi2_contingency(ctab)\n",
    "                test = \"Chi-square\"\n",
    "                n = int(ctab.values.sum())\n",
    "                effect_size = cramers_v(chi2, n, *ctab.shape)\n",
    "\n",
    "            results.append({\n",
    "                \"Outcome\": outcome_label,\n",
    "                \"Feature\": feature,\n",
    "                \"Test Used\": test,\n",
    "                \"P-Value\": p,\n",
    "                \"Effect Size\": effect_size\n",
    "            })\n",
    "\n",
    "        except Exception:\n",
    "            results.append({\n",
    "                \"Outcome\": outcome_label,\n",
    "                \"Feature\": feature,\n",
    "                \"Test Used\": \"Error\",\n",
    "                \"P-Value\": np.nan,\n",
    "                \"Effect Size\": np.nan\n",
    "            })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    if not results_df.empty:\n",
    "        mask = results_df[\"P-Value\"].notna()\n",
    "        if mask.any():\n",
    "            _, qvals, _, _ = multipletests(\n",
    "                results_df.loc[mask, \"P-Value\"],\n",
    "                alpha=0.05,\n",
    "                method=\"fdr_bh\"\n",
    "            )\n",
    "            results_df.loc[mask, \"Corrected P-Value\"] = qvals\n",
    "\n",
    "        results_df = results_df.sort_values([\"P-Value\"], na_position=\"last\")\n",
    "        results_df.to_excel(save_path, index=False)\n",
    "        print(f\"Univariate screening for {outcome_label} complete. Saved to:\\n   {save_path}\")\n",
    "    else:\n",
    "        print(f\"No valid univariate comparisons for {outcome_label}.\")\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3921bd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20984\\1771680675.py:110: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  results_df.to_excel(save_path, index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Univariate screening for Hospitalization complete. Saved to:\n",
      "   C:\\Users\\HP\\OneDrive\\Desktop\\Phase 2\\Binary Models\\univariate_hospitalization_with_effects.xlsx\n",
      "Univariate screening for Severe_ADR complete. Saved to:\n",
      "   C:\\Users\\HP\\OneDrive\\Desktop\\Phase 2\\Binary Models\\univariate_severeADR_with_effects.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20984\\1771680675.py:110: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  results_df.to_excel(save_path, index=False)\n"
     ]
    }
   ],
   "source": [
    "# Hospitalization (with effects)\n",
    "hosp_uni_path = os.path.join(\n",
    "    BASE_DIR,\n",
    "    \"univariate_hospitalization_with_effects.xlsx\"\n",
    ")\n",
    "hosp_uni_results = run_univariate_with_effects(\n",
    "    df=hosp_df,\n",
    "    outcome_col=\"hospitalization_flag_clean\",\n",
    "    feature_list=hosp_predictors,\n",
    "    outcome_label=\"Hospitalization\",\n",
    "    save_path=hosp_uni_path\n",
    ")\n",
    "\n",
    "# Severe ADR (with effects)\n",
    "adr_uni_path = os.path.join(\n",
    "    BASE_DIR,\n",
    "    \"univariate_severeADR_with_effects.xlsx\"\n",
    ")\n",
    "adr_uni_results = run_univariate_with_effects(\n",
    "    df=adr_model_df,\n",
    "    outcome_col=\"severe_adr_flag_clean\",\n",
    "    feature_list=adr_predictors,\n",
    "    outcome_label=\"Severe_ADR\",\n",
    "    save_path=adr_uni_path\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc0f8b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid univariate comparisons for Hospitalization.\n",
      "âœ… Univariate screening for Severe_ADR complete. Saved to:\n",
      "   C:\\Users\\HP\\OneDrive\\Desktop\\Phase 2\\Binary Models\\univariate_screening_severeADR_with_effects.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20984\\757564937.py:122: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  results_df.to_excel(save_path, index=False)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from math import sqrt\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper functions\n",
    "# ------------------------------------------------\n",
    "\n",
    "def is_binary(series):\n",
    "    vals = series.dropna().unique()\n",
    "    return len(vals) == 2\n",
    "\n",
    "# Cohen's d (for t-test)\n",
    "def cohens_d(x, y):\n",
    "    x = pd.to_numeric(x, errors=\"coerce\").dropna()\n",
    "    y = pd.to_numeric(y, errors=\"coerce\").dropna()\n",
    "    nx, ny = len(x), len(y)\n",
    "    if nx < 2 or ny < 2:\n",
    "        return np.nan\n",
    "    dof = nx + ny - 2\n",
    "    pooled_std = sqrt(((nx - 1) * x.var(ddof=1) + (ny - 1) * y.var(ddof=1)) / dof) if dof > 0 else np.nan\n",
    "    return (x.mean() - y.mean()) / pooled_std if (pooled_std is not None and pooled_std > 0) else np.nan\n",
    "\n",
    "# CramÃ©r's V (for Chi-square)\n",
    "def cramers_v(chi2, n, r, c):\n",
    "    if n == 0:\n",
    "        return np.nan\n",
    "    denom = n * (min(r - 1, c - 1))\n",
    "    if denom <= 0:\n",
    "        return np.nan\n",
    "    return sqrt(chi2 / denom)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Generic univariate screening for a single binary outcome\n",
    "# ------------------------------------------------\n",
    "\n",
    "def run_univariate_with_effects(df, outcome_col, feature_list, outcome_label, save_path):\n",
    "    data = df.copy()\n",
    "    # Ensure binary 0/1\n",
    "    data[outcome_col] = pd.to_numeric(data[outcome_col], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for feature in feature_list:\n",
    "        if feature not in data.columns:\n",
    "            continue\n",
    "\n",
    "        sub = data[[feature, outcome_col]].dropna()\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        x = sub[feature]\n",
    "        y = sub[outcome_col]\n",
    "\n",
    "        # Only sensible to continue if outcome is binary\n",
    "        if not is_binary(y):\n",
    "            continue\n",
    "\n",
    "        feat_is_num = np.issubdtype(x.dtype, np.number)\n",
    "\n",
    "        try:\n",
    "            # Numeric feature vs binary outcome -> t-test + Cohen's d\n",
    "            if feat_is_num:\n",
    "                groups = [x[y == val] for val in y.unique()]\n",
    "                if len(groups) != 2:\n",
    "                    continue\n",
    "                if len(groups[0]) < 2 or len(groups[1]) < 2:\n",
    "                    continue\n",
    "\n",
    "                t_stat, p = stats.ttest_ind(groups[0], groups[1], nan_policy=\"omit\", equal_var=False)\n",
    "                test = \"T-test\"\n",
    "                effect_size = cohens_d(groups[0], groups[1])\n",
    "\n",
    "            # Categorical feature vs binary outcome -> Chi-square + CramÃ©r's V\n",
    "            else:\n",
    "                ctab = pd.crosstab(x, y)\n",
    "                if ctab.shape[0] < 2 or ctab.shape[1] < 2:\n",
    "                    continue\n",
    "\n",
    "                chi2, p, dof, ex = stats.chi2_contingency(ctab)\n",
    "                test = \"Chi-square\"\n",
    "                n = int(ctab.values.sum())\n",
    "                effect_size = cramers_v(chi2, n, *ctab.shape)\n",
    "\n",
    "            results.append({\n",
    "                \"Outcome\": outcome_label,\n",
    "                \"Feature\": feature,\n",
    "                \"Test Used\": test,\n",
    "                \"P-Value\": p,\n",
    "                \"Effect Size\": effect_size\n",
    "            })\n",
    "\n",
    "        except Exception:\n",
    "            results.append({\n",
    "                \"Outcome\": outcome_label,\n",
    "                \"Feature\": feature,\n",
    "                \"Test Used\": \"Error\",\n",
    "                \"P-Value\": np.nan,\n",
    "                \"Effect Size\": np.nan\n",
    "            })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    if not results_df.empty:\n",
    "        # FDR correction\n",
    "        mask = results_df[\"P-Value\"].notna()\n",
    "        if mask.any():\n",
    "            _, qvals, _, _ = multipletests(\n",
    "                results_df.loc[mask, \"P-Value\"],\n",
    "                alpha=0.05,\n",
    "                method=\"fdr_bh\"\n",
    "            )\n",
    "            results_df.loc[mask, \"Corrected P-Value\"] = qvals\n",
    "\n",
    "        # Sort for readability\n",
    "        results_df = results_df.sort_values([\"P-Value\"], na_position=\"last\")\n",
    "\n",
    "        # Save\n",
    "        results_df.to_excel(save_path, index=False)\n",
    "        print(f\"âœ… Univariate screening for {outcome_label} complete. Saved to:\\n   {save_path}\")\n",
    "    else:\n",
    "        print(f\"No valid univariate comparisons for {outcome_label}.\")\n",
    "\n",
    "    return results_df\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Apply to your two models\n",
    "# ------------------------------------------------\n",
    "\n",
    "# Assuming BASE_DIR, hosp_df, adr_model_df, hosp_predictors, adr_predictors already exist\n",
    "\n",
    "# Hospitalization\n",
    "hosp_uni_path = os.path.join(BASE_DIR, \"univariate_screening_hospitalization_with_effects.xlsx\")\n",
    "hosp_uni_results = run_univariate_with_effects(\n",
    "    df=hosp_df,\n",
    "    outcome_col=\"hospitalization_flag\",\n",
    "    feature_list=hosp_predictors,\n",
    "    outcome_label=\"Hospitalization\",\n",
    "    save_path=hosp_uni_path\n",
    ")\n",
    "\n",
    "# Severe ADR\n",
    "adr_uni_path = os.path.join(BASE_DIR, \"univariate_screening_severeADR_with_effects.xlsx\")\n",
    "adr_uni_results = run_univariate_with_effects(\n",
    "    df=adr_model_df,\n",
    "    outcome_col=\"severe_adr_flag\",\n",
    "    feature_list=adr_predictors,\n",
    "    outcome_label=\"Severe_ADR\",\n",
    "    save_path=adr_uni_path\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdfe07e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizations completed! PNG files saved.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Where results were saved\n",
    "hosp_results_file = os.path.join(BASE_DIR, \"univariate_screening_hospitalization_with_effects.xlsx\")\n",
    "adr_results_file  = os.path.join(BASE_DIR, \"univariate_screening_severeADR_with_effects.xlsx\")\n",
    "\n",
    "hosp_uni_results = pd.read_excel(hosp_results_file)\n",
    "adr_uni_results  = pd.read_excel(adr_results_file)\n",
    "\n",
    "def plot_univariate_results(df, outcome_name, top_n=15, label_n=20):\n",
    "    df = df.copy()\n",
    "    \n",
    "    df = df[df[\"Corrected P-Value\"].notna()]\n",
    "    if df.empty:\n",
    "        print(f\"No valid univariate results for {outcome_name}.\")\n",
    "        return\n",
    "\n",
    "    # Create neg-log10 significance\n",
    "    df[\"neglog10_q\"] = -np.log10(df[\"Corrected P-Value\"].clip(lower=1e-300))\n",
    "    df[\"abs_effect\"] = df[\"Effect Size\"].abs()\n",
    "\n",
    "    # ----- Top N bar plot -----\n",
    "    top = df.sort_values(\"Corrected P-Value\").head(top_n)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.barh(top[\"Feature\"], top[\"neglog10_q\"])\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.xlabel(\"-log10(FDR q-value)\")\n",
    "    plt.title(f\"Top {top_n} Features - {outcome_name}\")\n",
    "    \n",
    "    # Annotate with test + effect size\n",
    "    for i, (_, row) in enumerate(top.iterrows()):\n",
    "        plt.text(row[\"neglog10_q\"], i, f\"  {row['Test Used']} | ES={row['Effect Size']:.2f}\", va=\"center\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(BASE_DIR, f\"univar_top{top_n}_{outcome_name}.png\"), dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    # ----- Volcano-style plot -----\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    plt.scatter(df[\"abs_effect\"], df[\"neglog10_q\"], alpha=0.6)\n",
    "    plt.xlabel(\"Absolute Effect Size\")\n",
    "    plt.ylabel(\"-log10(FDR q-value)\")\n",
    "    plt.title(f\"Effect Size vs Significance - {outcome_name}\")\n",
    "    \n",
    "    # Label top N by significance\n",
    "    label_top = df.sort_values(\"Corrected P-Value\").head(label_n)\n",
    "    for _, row in label_top.iterrows():\n",
    "        plt.text(row[\"abs_effect\"], row[\"neglog10_q\"], f\" {row['Feature']}\", fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(BASE_DIR, f\"univar_volcano_{outcome_name}.png\"), dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    # Return processed table\n",
    "    return df\n",
    "\n",
    "# Run to generate plots\n",
    "hosp_viz_df = plot_univariate_results(hosp_uni_results, \"Hospitalization\")\n",
    "adr_viz_df  = plot_univariate_results(adr_uni_results, \"Severe_ADR\")\n",
    "print(\"Visualizations completed! PNG files saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0100c5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heatmap saved successfully!\n"
     ]
    }
   ],
   "source": [
    "combined = pd.concat([hosp_viz_df, adr_viz_df], ignore_index=True)\n",
    "\n",
    "heat = combined.pivot_table(\n",
    "    index=\"Feature\",\n",
    "    columns=\"Outcome\",\n",
    "    values=\"abs_effect\",\n",
    "    aggfunc=\"max\"\n",
    ")\n",
    "\n",
    "keep = heat.max(axis=1).sort_values(ascending=False).head(40).index\n",
    "heat = heat.loc[keep]\n",
    "\n",
    "plt.figure(figsize=(10, 0.3*len(heat)+4))\n",
    "plt.imshow(heat.fillna(0).values, aspect=\"auto\")\n",
    "plt.colorbar(label=\"|Effect Size|\")\n",
    "plt.xticks(range(len(heat.columns)), heat.columns, rotation=45, ha=\"right\")\n",
    "plt.yticks(range(len(heat.index)), heat.index)\n",
    "plt.title(\"Effect Size Heatmap - Hospitalization & Severe ADR\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(BASE_DIR,\"univar_effectsize_heatmap_hosp_ADR.png\"), dpi=240)\n",
    "plt.close()\n",
    "\n",
    "print(\"Heatmap saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "019cb29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hospitalization shape: (406, 47)\n",
      "Severe ADR shape: (406, 46)\n",
      "\n",
      "Hosp. events:\n",
      "hospitalization_flag\n",
      "0    307\n",
      "1     99\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "Severe ADR events:\n",
      "severe_adr_flag\n",
      "0    209\n",
      "1     52\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "Missing hospital predictors: []\n",
      "Missing severe ADR predictors: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20984\\3190302576.py:66: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  hosp_df[\"hospitalization_flag\"]\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20984\\3190302576.py:171: RuntimeWarning: overflow encountered in exp\n",
      "  CI_high = np.exp(coef + 1.96 * se)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20984\\3190302576.py:253: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  uni_df.to_excel(out_path, index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Univariate] Saved: C:\\Users\\HP\\OneDrive\\Desktop\\Phase 2\\Binary Models\\binary_models\\univariate_logistic_Hospitalization_with_OR.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20984\\3190302576.py:171: RuntimeWarning: overflow encountered in exp\n",
      "  CI_high = np.exp(coef + 1.96 * se)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20984\\3190302576.py:253: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  uni_df.to_excel(out_path, index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Univariate] Saved: C:\\Users\\HP\\OneDrive\\Desktop\\Phase 2\\Binary Models\\binary_models\\univariate_logistic_SevereADR_with_OR.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20984\\3190302576.py:392: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  roc_points.to_excel(roc_points_path, index=False)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20984\\3190302576.py:393: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  pr_points.to_excel(pr_points_path, index=False)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20984\\3190302576.py:438: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  metrics.to_excel(metrics_path, index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Hospitalization] AUROC=0.581 (CI 0.516-0.643) | AUPRC=0.317 (CI 0.249-0.406)\n",
      "[Hospitalization] Saved metrics: C:\\Users\\HP\\OneDrive\\Desktop\\Phase 2\\Binary Models\\binary_models\\Hospitalization_multivariable_logistic_OOF_CV_metrics.xlsx\n",
      "[Hospitalization] Saved ROC plot: C:\\Users\\HP\\OneDrive\\Desktop\\Phase 2\\Binary Models\\binary_models\\Hospitalization_ROC_OOF_CV.png\n",
      "[Hospitalization] Saved PR plot : C:\\Users\\HP\\OneDrive\\Desktop\\Phase 2\\Binary Models\\binary_models\\Hospitalization_PR_OOF_CV.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20984\\3190302576.py:392: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  roc_points.to_excel(roc_points_path, index=False)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20984\\3190302576.py:393: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  pr_points.to_excel(pr_points_path, index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Severe_ADR] AUROC=0.549 (CI 0.461-0.640) | AUPRC=0.256 (CI 0.177-0.376)\n",
      "[Severe_ADR] Saved metrics: C:\\Users\\HP\\OneDrive\\Desktop\\Phase 2\\Binary Models\\binary_models\\Severe_ADR_multivariable_logistic_OOF_CV_metrics.xlsx\n",
      "[Severe_ADR] Saved ROC plot: C:\\Users\\HP\\OneDrive\\Desktop\\Phase 2\\Binary Models\\binary_models\\Severe_ADR_ROC_OOF_CV.png\n",
      "[Severe_ADR] Saved PR plot : C:\\Users\\HP\\OneDrive\\Desktop\\Phase 2\\Binary Models\\binary_models\\Severe_ADR_PR_OOF_CV.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20984\\3190302576.py:438: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  metrics.to_excel(metrics_path, index=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "      <th>N</th>\n",
       "      <th>Events</th>\n",
       "      <th>Event_Rate</th>\n",
       "      <th>AUROC_OOF_CV</th>\n",
       "      <th>AUROC_CI_2.5</th>\n",
       "      <th>AUROC_CI_97.5</th>\n",
       "      <th>AUPRC_OOF_CV</th>\n",
       "      <th>AUPRC_CI_2.5</th>\n",
       "      <th>AUPRC_CI_97.5</th>\n",
       "      <th>Brier</th>\n",
       "      <th>Threshold_F1_opt</th>\n",
       "      <th>Accuracy_at_t</th>\n",
       "      <th>Precision_at_t</th>\n",
       "      <th>Recall_at_t</th>\n",
       "      <th>F1_at_t</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hospitalization</td>\n",
       "      <td>406</td>\n",
       "      <td>99</td>\n",
       "      <td>0.243842</td>\n",
       "      <td>0.580594</td>\n",
       "      <td>0.516418</td>\n",
       "      <td>0.643142</td>\n",
       "      <td>0.317176</td>\n",
       "      <td>0.248958</td>\n",
       "      <td>0.406417</td>\n",
       "      <td>0.200428</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.44335</td>\n",
       "      <td>0.274021</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.405263</td>\n",
       "      <td>103</td>\n",
       "      <td>204</td>\n",
       "      <td>22</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Outcome    N  Events  Event_Rate  AUROC_OOF_CV  AUROC_CI_2.5  \\\n",
       "0  Hospitalization  406      99    0.243842      0.580594      0.516418   \n",
       "\n",
       "   AUROC_CI_97.5  AUPRC_OOF_CV  AUPRC_CI_2.5  AUPRC_CI_97.5     Brier  \\\n",
       "0       0.643142      0.317176      0.248958       0.406417  0.200428   \n",
       "\n",
       "   Threshold_F1_opt  Accuracy_at_t  Precision_at_t  Recall_at_t   F1_at_t  \\\n",
       "0              0.15        0.44335        0.274021     0.777778  0.405263   \n",
       "\n",
       "    TN   FP  FN  TP  \n",
       "0  103  204  22  77  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "      <th>N</th>\n",
       "      <th>Events</th>\n",
       "      <th>Event_Rate</th>\n",
       "      <th>AUROC_OOF_CV</th>\n",
       "      <th>AUROC_CI_2.5</th>\n",
       "      <th>AUROC_CI_97.5</th>\n",
       "      <th>AUPRC_OOF_CV</th>\n",
       "      <th>AUPRC_CI_2.5</th>\n",
       "      <th>AUPRC_CI_97.5</th>\n",
       "      <th>Brier</th>\n",
       "      <th>Threshold_F1_opt</th>\n",
       "      <th>Accuracy_at_t</th>\n",
       "      <th>Precision_at_t</th>\n",
       "      <th>Recall_at_t</th>\n",
       "      <th>F1_at_t</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Severe_ADR</td>\n",
       "      <td>261</td>\n",
       "      <td>52</td>\n",
       "      <td>0.199234</td>\n",
       "      <td>0.548951</td>\n",
       "      <td>0.460971</td>\n",
       "      <td>0.639623</td>\n",
       "      <td>0.255957</td>\n",
       "      <td>0.176689</td>\n",
       "      <td>0.375774</td>\n",
       "      <td>0.175475</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.298851</td>\n",
       "      <td>0.213974</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.348754</td>\n",
       "      <td>29</td>\n",
       "      <td>180</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Outcome    N  Events  Event_Rate  AUROC_OOF_CV  AUROC_CI_2.5  \\\n",
       "0  Severe_ADR  261      52    0.199234      0.548951      0.460971   \n",
       "\n",
       "   AUROC_CI_97.5  AUPRC_OOF_CV  AUPRC_CI_2.5  AUPRC_CI_97.5     Brier  \\\n",
       "0       0.639623      0.255957      0.176689       0.375774  0.175475   \n",
       "\n",
       "   Threshold_F1_opt  Accuracy_at_t  Precision_at_t  Recall_at_t   F1_at_t  TN  \\\n",
       "0              0.03       0.298851        0.213974     0.942308  0.348754  29   \n",
       "\n",
       "    FP  FN  TP  \n",
       "0  180   3  49  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DONE. Outputs saved in: C:\\Users\\HP\\OneDrive\\Desktop\\Phase 2\\Binary Models\\binary_models\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# VERO Phase 2 Binary Models (Clean + Defensible)\n",
    "# - Keeps your outcome cleaning logic unchanged\n",
    "# - Keeps your predictor lists unchanged\n",
    "# - Adds robust CV evaluation + cleaner exports\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    StratifiedKFold,\n",
    "    RepeatedStratifiedKFold,\n",
    "    GridSearchCV,\n",
    "    cross_val_predict\n",
    ")\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    roc_curve,\n",
    "    precision_recall_curve,\n",
    "    confusion_matrix,\n",
    "    brier_score_loss\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 0) Paths\n",
    "# ------------------------------------------------------------\n",
    "BASE_DIR = r\"C:\\Users\\HP\\OneDrive\\Desktop\\Phase 1\\Clean Data\"\n",
    "hosp_path = os.path.join(BASE_DIR, \"hospitalization_model_matrix_imputed_v1.csv\")\n",
    "adr_path  = os.path.join(BASE_DIR, \"severe_adr_model_matrix_imputed_v1.csv\")\n",
    "\n",
    "OUT_BASE_DIR = r\"C:\\Users\\HP\\OneDrive\\Desktop\\Phase 2\\Binary Models\"\n",
    "BIN_OUT_DIR  = os.path.join(OUT_BASE_DIR, \"binary_models\")\n",
    "os.makedirs(BIN_OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) Load data\n",
    "# ------------------------------------------------------------\n",
    "hosp_df = pd.read_csv(hosp_path)\n",
    "adr_df  = pd.read_csv(adr_path)\n",
    "\n",
    "print(\"Hospitalization shape:\", hosp_df.shape)\n",
    "print(\"Severe ADR shape:\", adr_df.shape)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) LOCKED cleaning logic (DO NOT CHANGE)\n",
    "# ------------------------------------------------------------\n",
    "yes_no_map = {\n",
    "    \"yes\": 1, \"y\": 1, \"1\": 1, 1: 1, True: 1,\n",
    "    \"no\": 0, \"n\": 0, \"0\": 0, 0: 0, False: 0\n",
    "}\n",
    "\n",
    "# --- HOSPITALIZATION FLAG ---\n",
    "hosp_df[\"hospitalization_flag\"] = (\n",
    "    hosp_df[\"hospitalization_flag\"]\n",
    "    .astype(str)\n",
    "    .str.lower()\n",
    "    .str.strip()\n",
    "    .replace(yes_no_map)\n",
    ")\n",
    "hosp_df[\"hospitalization_flag\"] = pd.to_numeric(\n",
    "    hosp_df[\"hospitalization_flag\"], errors=\"coerce\"\n",
    ").astype(\"Int64\")\n",
    "hosp_df = hosp_df[hosp_df[\"hospitalization_flag\"].isin([0, 1])]\n",
    "\n",
    "# --- SEVERE ADR FLAG ---\n",
    "adr_model_df = adr_df.copy()\n",
    "adr_model_df[\"severe_adr_flag\"] = (\n",
    "    adr_model_df[\"severe_adr_flag\"]\n",
    "    .astype(str)\n",
    "    .str.lower()\n",
    "    .str.strip()\n",
    "    .replace(yes_no_map)\n",
    ")\n",
    "adr_model_df[\"severe_adr_flag\"] = pd.to_numeric(\n",
    "    adr_model_df[\"severe_adr_flag\"], errors=\"coerce\"\n",
    ").astype(\"Int64\")\n",
    "adr_model_df = adr_model_df[adr_model_df[\"severe_adr_flag\"].isin([0, 1])]\n",
    "\n",
    "# Summary (these should match your screenshot)\n",
    "print(\"\\nHosp. events:\")\n",
    "print(hosp_df[\"hospitalization_flag\"].value_counts(dropna=False))\n",
    "\n",
    "print(\"\\nSevere ADR events:\")\n",
    "print(adr_model_df[\"severe_adr_flag\"].value_counts(dropna=False))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) LOCKED predictors (DO NOT CHANGE)\n",
    "# ------------------------------------------------------------\n",
    "hosp_predictors = [\n",
    "    \"age_group\",\"gender\",\"ethnicity\",\"education_level\",\"employment_status\",\"bmi_category\",\n",
    "    \"smoking_status_detail\",\"alcohol_consumption\",\n",
    "    \"IPB\",\"cci_score\",\n",
    "    \"anemia_comorbidity\",\"asthma\",\"atrial_fibrillation\",\"copd\",\"depressive_syndrome\",\n",
    "    \"diabete_tipo_II\",\"dyslipidemia\",\"hypertension\",\"hypertensive_heart_disease\",\n",
    "    \"ischemic_heart_disease\",\"renal_insufficiency\",\"obesity_comorbidity\",\"psychiatric_disorders\",\n",
    "    \"cardiovascular_disorders\",\"cerebrovascular_disorders\",\"gastrointestinal_disorders\",\n",
    "    \"gastroesophageal_reflux_full\",\"aortic_insufficiency\",\n",
    "    \"alt_gpt_range\",\"ast_got_range\",\"creatinine_range\",\"direct_bilirubin_range\",\n",
    "    \"total_bilirubin_range\",\"hemoglobin_range\",\"platelet_count_range\",\"white_blood_cells_range\",\n",
    "    \"red_blood_cells_range\",\"neutrophils_percent_range\",\n",
    "    \"tumor_type\",\"molecular_alterations\",\"mutations_present\",\"genotipo_DPYD_type\"\n",
    "]\n",
    "\n",
    "adr_predictors = [\n",
    "    \"age_group\",\"gender\",\"ethnicity\",\"education_level\",\"employment_status\",\"bmi_category\",\n",
    "    \"smoking_status_detail\",\"alcohol_consumption\",\n",
    "    \"IPB\",\"cci_score\",\n",
    "    \"anemia_comorbidity\",\"asthma\",\"atrial_fibrillation\",\"copd\",\"depressive_syndrome\",\n",
    "    \"diabete_tipo_II\",\"dyslipidemia\",\"hypertension\",\"hypertensive_heart_disease\",\n",
    "    \"ischemic_heart_disease\",\"renal_insufficiency\",\"obesity_comorbidity\",\"psychiatric_disorders\",\n",
    "    \"cardiovascular_disorders\",\"cerebrovascular_disorders\",\"gastrointestinal_disorders\",\n",
    "    \"gastroesophageal_reflux_full\",\"aortic_insufficiency\",\n",
    "    \"alt_gpt_range\",\"ast_got_range\",\"creatinine_range\",\"direct_bilirubin_range\",\n",
    "    \"total_bilirubin_range\",\"hemoglobin_range\",\"platelet_count_range\",\"white_blood_cells_range\",\n",
    "    \"red_blood_cells_range\",\"neutrophils_percent_range\",\n",
    "    \"tumor_type\",\"molecular_alterations\",\"mutations_present\",\"genotipo_DPYD_type\",\n",
    "    \"farmaci_cat_n\"\n",
    "]\n",
    "\n",
    "missing_h = [c for c in hosp_predictors if c not in hosp_df.columns]\n",
    "missing_a = [c for c in adr_predictors if c not in adr_model_df.columns]\n",
    "print(\"\\nMissing hospital predictors:\", missing_h)\n",
    "print(\"Missing severe ADR predictors:\", missing_a)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) Univariate logistic (statsmodels): OR + CI + p + FDR\n",
    "# ------------------------------------------------------------\n",
    "def run_univariate_logistic_statsmodels(df, y_col, predictors, outcome_name, out_path):\n",
    "    y = df[y_col].astype(int)\n",
    "    rows = []\n",
    "\n",
    "    for var in predictors:\n",
    "        if var not in df.columns:\n",
    "            continue\n",
    "\n",
    "        x = df[var]\n",
    "        sub = df[[y_col, var]].dropna()\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        y_sub = sub[y_col].astype(int)\n",
    "        x_sub = sub[var]\n",
    "\n",
    "        if y_sub.nunique() != 2:\n",
    "            continue\n",
    "\n",
    "        # numeric predictor\n",
    "        if pd.api.types.is_numeric_dtype(x_sub):\n",
    "            if x_sub.nunique() < 2:\n",
    "                continue\n",
    "            X = sm.add_constant(x_sub.astype(float))\n",
    "            try:\n",
    "                model = sm.Logit(y_sub, X).fit(disp=False)\n",
    "                coef = model.params[var]\n",
    "                se = model.bse[var]\n",
    "                p = model.pvalues[var]\n",
    "                OR = np.exp(coef)\n",
    "                CI_low = np.exp(coef - 1.96 * se)\n",
    "                CI_high = np.exp(coef + 1.96 * se)\n",
    "                rows.append({\n",
    "                    \"Outcome\": outcome_name,\n",
    "                    \"Predictor\": var,\n",
    "                    \"Level\": \"per unit\",\n",
    "                    \"coef\": coef,\n",
    "                    \"OR\": OR,\n",
    "                    \"CI_low\": CI_low,\n",
    "                    \"CI_high\": CI_high,\n",
    "                    \"p_value\": p\n",
    "                })\n",
    "            except Exception as e:\n",
    "                rows.append({\n",
    "                    \"Outcome\": outcome_name,\n",
    "                    \"Predictor\": var,\n",
    "                    \"Level\": \"ERROR\",\n",
    "                    \"coef\": np.nan,\n",
    "                    \"OR\": np.nan,\n",
    "                    \"CI_low\": np.nan,\n",
    "                    \"CI_high\": np.nan,\n",
    "                    \"p_value\": np.nan,\n",
    "                    \"Error\": str(e)\n",
    "                })\n",
    "        else:\n",
    "            # categorical predictor: most frequent ref\n",
    "            vc = x_sub.value_counts(dropna=True)\n",
    "            if vc.shape[0] < 2:\n",
    "                continue\n",
    "            ref = vc.idxmax()\n",
    "\n",
    "            dummies = pd.get_dummies(x_sub, drop_first=False)\n",
    "            if ref in dummies.columns:\n",
    "                dummies = dummies.drop(columns=[ref])\n",
    "\n",
    "            if dummies.shape[1] == 0:\n",
    "                continue\n",
    "\n",
    "            X = sm.add_constant(dummies)\n",
    "            try:\n",
    "                model = sm.Logit(y_sub, X).fit(disp=False)\n",
    "                for lvl in dummies.columns:\n",
    "                    coef = model.params[lvl]\n",
    "                    se = model.bse[lvl]\n",
    "                    p = model.pvalues[lvl]\n",
    "                    OR = np.exp(coef)\n",
    "                    CI_low = np.exp(coef - 1.96 * se)\n",
    "                    CI_high = np.exp(coef + 1.96 * se)\n",
    "                    rows.append({\n",
    "                        \"Outcome\": outcome_name,\n",
    "                        \"Predictor\": var,\n",
    "                        \"Level\": f\"{lvl} vs {ref}\",\n",
    "                        \"coef\": coef,\n",
    "                        \"OR\": OR,\n",
    "                        \"CI_low\": CI_low,\n",
    "                        \"CI_high\": CI_high,\n",
    "                        \"p_value\": p\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                rows.append({\n",
    "                    \"Outcome\": outcome_name,\n",
    "                    \"Predictor\": var,\n",
    "                    \"Level\": \"ERROR\",\n",
    "                    \"coef\": np.nan,\n",
    "                    \"OR\": np.nan,\n",
    "                    \"CI_low\": np.nan,\n",
    "                    \"CI_high\": np.nan,\n",
    "                    \"p_value\": np.nan,\n",
    "                    \"Error\": str(e)\n",
    "                })\n",
    "\n",
    "    uni_df = pd.DataFrame(rows)\n",
    "    if uni_df.empty:\n",
    "        print(f\"[Univariate] No valid models for {outcome_name}\")\n",
    "        return uni_df\n",
    "\n",
    "    # FDR correction\n",
    "    mask = uni_df[\"p_value\"].notna()\n",
    "    if mask.any():\n",
    "        _, qvals, _, _ = multipletests(uni_df.loc[mask, \"p_value\"], method=\"fdr_bh\")\n",
    "        uni_df.loc[mask, \"q_value_fdr_bh\"] = qvals\n",
    "\n",
    "    uni_df = uni_df.sort_values([\"p_value\"], na_position=\"last\")\n",
    "    uni_df.to_excel(out_path, index=False)\n",
    "    print(f\"[Univariate] Saved: {out_path}\")\n",
    "    return uni_df\n",
    "\n",
    "hosp_uni_path = os.path.join(BIN_OUT_DIR, \"univariate_logistic_Hospitalization_with_OR.xlsx\")\n",
    "adr_uni_path  = os.path.join(BIN_OUT_DIR, \"univariate_logistic_SevereADR_with_OR.xlsx\")\n",
    "\n",
    "hosp_uni = run_univariate_logistic_statsmodels(\n",
    "    df=hosp_df,\n",
    "    y_col=\"hospitalization_flag\",\n",
    "    predictors=hosp_predictors,\n",
    "    outcome_name=\"Hospitalization\",\n",
    "    out_path=hosp_uni_path\n",
    ")\n",
    "\n",
    "adr_uni = run_univariate_logistic_statsmodels(\n",
    "    df=adr_model_df,\n",
    "    y_col=\"severe_adr_flag\",\n",
    "    predictors=adr_predictors,\n",
    "    outcome_name=\"Severe_ADR\",\n",
    "    out_path=adr_uni_path\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5) Multivariable logistic with Repeated CV + tuning + CI\n",
    "# ------------------------------------------------------------\n",
    "def infer_cols(X: pd.DataFrame):\n",
    "    numeric_cols = [c for c in X.columns if np.issubdtype(X[c].dtype, np.number)]\n",
    "    cat_cols = [c for c in X.columns if c not in numeric_cols]\n",
    "    return numeric_cols, cat_cols\n",
    "\n",
    "def build_pipeline(numeric_cols, cat_cols):\n",
    "    pre = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", StandardScaler(), numeric_cols),\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "\n",
    "    # L2 logistic (still logistic, stable baseline)\n",
    "    clf = LogisticRegression(\n",
    "        max_iter=5000,\n",
    "        solver=\"lbfgs\"\n",
    "    )\n",
    "\n",
    "    return Pipeline([(\"pre\", pre), (\"clf\", clf)])\n",
    "\n",
    "def best_threshold_f1(y_true, y_prob):\n",
    "    thresholds = np.linspace(0.01, 0.99, 99)\n",
    "    best_t, best_f1 = 0.5, -1.0\n",
    "    for t in thresholds:\n",
    "        pred = (y_prob >= t).astype(int)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, pred).ravel()\n",
    "        precision = tp / (tp + fp) if (tp + fp) else 0.0\n",
    "        recall    = tp / (tp + fn) if (tp + fn) else 0.0\n",
    "        f1 = (2 * precision * recall / (precision + recall)) if (precision + recall) else 0.0\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_t = float(t)\n",
    "    return best_t, best_f1\n",
    "\n",
    "def bootstrap_ci(y_true, y_prob, metric_fn, n_boot=2000, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_prob = np.asarray(y_prob)\n",
    "    n = len(y_true)\n",
    "    vals = []\n",
    "    for _ in range(n_boot):\n",
    "        idx = rng.integers(0, n, n)\n",
    "        yt = y_true[idx]\n",
    "        yp = y_prob[idx]\n",
    "        if len(np.unique(yt)) < 2:\n",
    "            continue\n",
    "        vals.append(metric_fn(yt, yp))\n",
    "    if len(vals) < 50:\n",
    "        return (np.nan, np.nan)\n",
    "    lo, hi = np.percentile(vals, [2.5, 97.5])\n",
    "    return float(lo), float(hi)\n",
    "\n",
    "def run_multivariable_logistic_cv(df, y_col, predictors, outcome_name, out_dir,\n",
    "                                 n_splits=5, random_state=42):\n",
    "    cols = [c for c in predictors if c in df.columns]\n",
    "    X = df[cols].copy()\n",
    "\n",
    "    # Use cleaned outcome already in df, but be safe\n",
    "    y = pd.to_numeric(df[y_col], errors=\"coerce\")\n",
    "    keep = y.isin([0, 1])\n",
    "    X = X.loc[keep].copy()\n",
    "    y = y.loc[keep].astype(int)\n",
    "\n",
    "    if y.nunique() != 2:\n",
    "        raise ValueError(f\"[{outcome_name}] Outcome not binary after filtering.\")\n",
    "\n",
    "    numeric_cols, cat_cols = infer_cols(X)\n",
    "    pipe = build_pipeline(numeric_cols, cat_cols)\n",
    "\n",
    "    # Tune C (regularization strength)\n",
    "    param_grid = {\"clf__C\": np.logspace(-3, 2, 10)}\n",
    "    cv_inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    search = GridSearchCV(pipe, param_grid=param_grid, scoring=\"roc_auc\", cv=cv_inner, n_jobs=-1)\n",
    "\n",
    "    # IMPORTANT: cross_val_predict needs a partition CV (each sample predicted once)\n",
    "    cv_outer = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    y_prob = cross_val_predict(\n",
    "        search, X, y,\n",
    "        cv=cv_outer,\n",
    "        method=\"predict_proba\",\n",
    "        n_jobs=-1\n",
    "    )[:, 1]\n",
    "\n",
    "    # Threshold-free metrics\n",
    "    auc = roc_auc_score(y, y_prob)\n",
    "    ap  = average_precision_score(y, y_prob)\n",
    "    brier = brier_score_loss(y, y_prob)\n",
    "\n",
    "    auc_ci = bootstrap_ci(y, y_prob, roc_auc_score)\n",
    "    ap_ci  = bootstrap_ci(y, y_prob, average_precision_score)\n",
    "\n",
    "    # Thresholded metrics (report with stated threshold)\n",
    "    t_star, f1_star = best_threshold_f1(y, y_prob)\n",
    "    y_pred = (y_prob >= t_star).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) else 0.0\n",
    "    recall    = tp / (tp + fn) if (tp + fn) else 0.0\n",
    "    acc       = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "    # Curves\n",
    "    fpr, tpr, _ = roc_curve(y, y_prob)\n",
    "    pr_prec, pr_rec, _ = precision_recall_curve(y, y_prob)\n",
    "\n",
    "    # Save curve points\n",
    "    roc_points = pd.DataFrame({\"FPR\": fpr, \"TPR\": tpr})\n",
    "    pr_points  = pd.DataFrame({\"Recall\": pr_rec, \"Precision\": pr_prec})\n",
    "\n",
    "    roc_points_path = os.path.join(out_dir, f\"{outcome_name}_ROC_points_OOF_CV.xlsx\")\n",
    "    pr_points_path  = os.path.join(out_dir, f\"{outcome_name}_PR_points_OOF_CV.xlsx\")\n",
    "    roc_points.to_excel(roc_points_path, index=False)\n",
    "    pr_points.to_excel(pr_points_path, index=False)\n",
    "\n",
    "    # Plots\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f\"ROC (OOF CV) - {outcome_name} | AUC={auc:.3f}\")\n",
    "    plt.tight_layout()\n",
    "    roc_png = os.path.join(out_dir, f\"{outcome_name}_ROC_OOF_CV.png\")\n",
    "    plt.savefig(roc_png, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.plot(pr_rec, pr_prec)\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.title(f\"PR (OOF CV) - {outcome_name} | AP={ap:.3f}\")\n",
    "    plt.tight_layout()\n",
    "    pr_png = os.path.join(out_dir, f\"{outcome_name}_PR_OOF_CV.png\")\n",
    "    plt.savefig(pr_png, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    metrics = pd.DataFrame([{\n",
    "        \"Outcome\": outcome_name,\n",
    "        \"N\": int(len(y)),\n",
    "        \"Events\": int(y.sum()),\n",
    "        \"Event_Rate\": float(y.mean()),\n",
    "        \"AUROC_OOF_CV\": float(auc),\n",
    "        \"AUROC_CI_2.5\": auc_ci[0],\n",
    "        \"AUROC_CI_97.5\": auc_ci[1],\n",
    "        \"AUPRC_OOF_CV\": float(ap),\n",
    "        \"AUPRC_CI_2.5\": ap_ci[0],\n",
    "        \"AUPRC_CI_97.5\": ap_ci[1],\n",
    "        \"Brier\": float(brier),\n",
    "        \"Threshold_F1_opt\": float(t_star),\n",
    "        \"Accuracy_at_t\": float(acc),\n",
    "        \"Precision_at_t\": float(precision),\n",
    "        \"Recall_at_t\": float(recall),\n",
    "        \"F1_at_t\": float(f1_star),\n",
    "        \"TN\": int(tn), \"FP\": int(fp), \"FN\": int(fn), \"TP\": int(tp)\n",
    "    }])\n",
    "\n",
    "    metrics_path = os.path.join(out_dir, f\"{outcome_name}_multivariable_logistic_OOF_CV_metrics.xlsx\")\n",
    "    metrics.to_excel(metrics_path, index=False)\n",
    "\n",
    "    print(f\"\\n[{outcome_name}] AUROC={auc:.3f} (CI {auc_ci[0]:.3f}-{auc_ci[1]:.3f}) | \"\n",
    "          f\"AUPRC={ap:.3f} (CI {ap_ci[0]:.3f}-{ap_ci[1]:.3f})\")\n",
    "    print(f\"[{outcome_name}] Saved metrics: {metrics_path}\")\n",
    "    print(f\"[{outcome_name}] Saved ROC plot: {roc_png}\")\n",
    "    print(f\"[{outcome_name}] Saved PR plot : {pr_png}\")\n",
    "\n",
    "    return metrics\n",
    "\n",
    "hosp_metrics = run_multivariable_logistic_cv(\n",
    "    df=hosp_df,\n",
    "    y_col=\"hospitalization_flag\",\n",
    "    predictors=hosp_predictors,\n",
    "    outcome_name=\"Hospitalization\",\n",
    "    out_dir=BIN_OUT_DIR\n",
    ")\n",
    "\n",
    "adr_metrics = run_multivariable_logistic_cv(\n",
    "    df=adr_model_df,\n",
    "    y_col=\"severe_adr_flag\",\n",
    "    predictors=adr_predictors,\n",
    "    outcome_name=\"Severe_ADR\",\n",
    "    out_dir=BIN_OUT_DIR\n",
    ")\n",
    "\n",
    "\n",
    "display(hosp_metrics)\n",
    "display(adr_metrics)\n",
    "\n",
    "print(\"\\nDONE. Outputs saved in:\", BIN_OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2927f6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Hospitalization] done: Logistic_L2 | AUROC=0.567\n",
      "[Hospitalization] done: ElasticNet_Logit | AUROC=0.598\n",
      "[Hospitalization] done: RandomForest | AUROC=0.601\n",
      "[Hospitalization] done: GradientBoosting | AUROC=0.574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20984\\3561750615.py:112: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  pd.DataFrame({\"FPR\": fpr, \"TPR\": tpr, \"Threshold\": thr}).to_excel(out_points_xlsx, index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Hospitalization] Single export saved to: C:\\Users\\HP\\OneDrive\\Desktop\\Phase 2\\Binary Models\\Hospitalization_PHASE2_EXPORT.xlsx\n",
      "[Severe_ADR] done: Logistic_L2 | AUROC=0.541\n",
      "[Severe_ADR] done: ElasticNet_Logit | AUROC=0.541\n",
      "[Severe_ADR] done: RandomForest | AUROC=0.624\n",
      "[Severe_ADR] done: GradientBoosting | AUROC=0.615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20984\\3561750615.py:112: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  pd.DataFrame({\"FPR\": fpr, \"TPR\": tpr, \"Threshold\": thr}).to_excel(out_points_xlsx, index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Severe_ADR] Single export saved to: C:\\Users\\HP\\OneDrive\\Desktop\\Phase 2\\Binary Models\\Severe_ADR_PHASE2_EXPORT.xlsx\n",
      "\n",
      "DONE\n",
      "Hospitalization package: {'outcome': 'Hospitalization', 'export_xlsx': 'C:\\\\Users\\\\HP\\\\OneDrive\\\\Desktop\\\\Phase 2\\\\Binary Models\\\\Hospitalization_PHASE2_EXPORT.xlsx', 'best_overall': 'RandomForest', 'best_linear': 'ElasticNet_Logit', 'roc_png': 'C:\\\\Users\\\\HP\\\\OneDrive\\\\Desktop\\\\Phase 2\\\\Binary Models\\\\Plots\\\\Hospitalization_BEST_ROC.png', 'model_joblib': 'C:\\\\Users\\\\HP\\\\OneDrive\\\\Desktop\\\\Phase 2\\\\Binary Models\\\\Hospitalization_BEST_model_pipeline.joblib'}\n",
      "Severe ADR package: {'outcome': 'Severe_ADR', 'export_xlsx': 'C:\\\\Users\\\\HP\\\\OneDrive\\\\Desktop\\\\Phase 2\\\\Binary Models\\\\Severe_ADR_PHASE2_EXPORT.xlsx', 'best_overall': 'RandomForest', 'best_linear': 'ElasticNet_Logit', 'roc_png': 'C:\\\\Users\\\\HP\\\\OneDrive\\\\Desktop\\\\Phase 2\\\\Binary Models\\\\Plots\\\\Severe_ADR_BEST_ROC.png', 'model_joblib': 'C:\\\\Users\\\\HP\\\\OneDrive\\\\Desktop\\\\Phase 2\\\\Binary Models\\\\Severe_ADR_BEST_model_pipeline.joblib'}\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Phase 2 (Binary): Clean model comparison + BEST ROC + Coefs\n",
    "# One clean export package per outcome\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_predict\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score,\n",
    "    roc_curve, brier_score_loss\n",
    ")\n",
    "\n",
    "# ---------------------------\n",
    "# OUTPUT DIRS (as requested)\n",
    "# ---------------------------\n",
    "OUT_DIR = r\"C:\\Users\\HP\\OneDrive\\Desktop\\Phase 2\\Binary Models\"\n",
    "PLOTS_DIR = os.path.join(OUT_DIR, \"Plots\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "\n",
    "# ---------------------------\n",
    "# Helpers\n",
    "# ---------------------------\n",
    "def infer_cols(X: pd.DataFrame):\n",
    "    numeric_cols = [c for c in X.columns if np.issubdtype(X[c].dtype, np.number)]\n",
    "    cat_cols = [c for c in X.columns if c not in numeric_cols]\n",
    "    return numeric_cols, cat_cols\n",
    "\n",
    "def make_preprocessor(X: pd.DataFrame, dense_for_trees: bool):\n",
    "    num_cols, cat_cols = infer_cols(X)\n",
    "\n",
    "    if dense_for_trees:\n",
    "        ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "        num_tf = \"passthrough\"\n",
    "    else:\n",
    "        ohe = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "        num_tf = StandardScaler()\n",
    "\n",
    "    transformers = []\n",
    "    if num_cols:\n",
    "        transformers.append((\"num\", num_tf, num_cols))\n",
    "    if cat_cols:\n",
    "        transformers.append((\"cat\", ohe, cat_cols))\n",
    "\n",
    "    return ColumnTransformer(transformers=transformers, remainder=\"drop\")\n",
    "\n",
    "def bootstrap_ci_auc(y_true, y_prob, n_boot=1500, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_prob = np.asarray(y_prob)\n",
    "    n = len(y_true)\n",
    "    vals = []\n",
    "\n",
    "    for _ in range(n_boot):\n",
    "        idx = rng.integers(0, n, n)\n",
    "        yt = y_true[idx]\n",
    "        yp = y_prob[idx]\n",
    "        if len(np.unique(yt)) < 2:\n",
    "            continue\n",
    "        vals.append(roc_auc_score(yt, yp))\n",
    "\n",
    "    if len(vals) < 50:\n",
    "        return (np.nan, np.nan)\n",
    "\n",
    "    lo, hi = np.percentile(vals, [2.5, 97.5])\n",
    "    return float(lo), float(hi)\n",
    "\n",
    "def compute_metrics(y_true, y_prob, outcome_name, model_name):\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "    ap  = average_precision_score(y_true, y_prob)\n",
    "    brier = brier_score_loss(y_true, y_prob)\n",
    "    auc_lo, auc_hi = bootstrap_ci_auc(y_true, y_prob)\n",
    "\n",
    "    return {\n",
    "        \"Outcome\": outcome_name,\n",
    "        \"Model\": model_name,\n",
    "        \"N\": int(len(y_true)),\n",
    "        \"Events\": int(np.sum(y_true)),\n",
    "        \"Event_Rate\": float(np.mean(y_true)),\n",
    "        \"AUROC\": float(auc),\n",
    "        \"AUROC_CI_2.5\": auc_lo,\n",
    "        \"AUROC_CI_97.5\": auc_hi,\n",
    "        \"AUPRC\": float(ap),\n",
    "        \"Brier\": float(brier),\n",
    "    }\n",
    "\n",
    "def pick_best_overall(results_df: pd.DataFrame):\n",
    "    tmp = results_df.sort_values([\"AUROC\", \"AUPRC\", \"Brier\"], ascending=[False, False, True])\n",
    "    return tmp.iloc[0][\"Model\"]\n",
    "\n",
    "def pick_best_linear(results_df: pd.DataFrame):\n",
    "    linear = results_df[results_df[\"Model\"].isin([\"Logistic_L2\", \"ElasticNet_Logit\"])].copy()\n",
    "    if linear.empty:\n",
    "        return None\n",
    "    linear = linear.sort_values([\"AUROC\", \"AUPRC\", \"Brier\"], ascending=[False, False, True])\n",
    "    return linear.iloc[0][\"Model\"]\n",
    "\n",
    "def plot_best_roc(y_true, y_prob, outcome_name, best_model_name, out_png, out_points_xlsx):\n",
    "    fpr, tpr, thr = roc_curve(y_true, y_prob)\n",
    "    pd.DataFrame({\"FPR\": fpr, \"TPR\": tpr, \"Threshold\": thr}).to_excel(out_points_xlsx, index=False)\n",
    "\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "    ap  = average_precision_score(y_true, y_prob)\n",
    "    brier = brier_score_loss(y_true, y_prob)\n",
    "    auc_lo, auc_hi = bootstrap_ci_auc(y_true, y_prob)\n",
    "\n",
    "    annotate_text = (\n",
    "        f\"Model: {best_model_name}\\n\"\n",
    "        f\"AUROC: {auc:.3f} (95% CI {auc_lo:.3f}-{auc_hi:.3f})\\n\"\n",
    "        f\"AUPRC: {ap:.3f}\\n\"\n",
    "        f\"Brier: {brier:.3f}\"\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    plt.plot(fpr, tpr, linewidth=2)\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\", linewidth=1)\n",
    "\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f\"ROC (OOF CV) - {outcome_name}\")\n",
    "\n",
    "    plt.text(\n",
    "        0.58, 0.20,\n",
    "        annotate_text,\n",
    "        fontsize=10,\n",
    "        bbox=dict(boxstyle=\"round\", alpha=0.15)\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=220)\n",
    "    plt.close()\n",
    "\n",
    "def extract_linear_coefficients(gridsearch_obj: GridSearchCV):\n",
    "    \"\"\"\n",
    "    Output columns exactly like your snapshot:\n",
    "      feature | coef | OR\n",
    "    \"\"\"\n",
    "    best_pipe = gridsearch_obj.best_estimator_\n",
    "    pre = best_pipe.named_steps[\"pre\"]\n",
    "    clf = best_pipe.named_steps[\"clf\"]\n",
    "\n",
    "    try:\n",
    "        feat_names = pre.get_feature_names_out()\n",
    "        feat_names = [str(f) for f in feat_names]\n",
    "    except Exception:\n",
    "        feat_names = [f\"X{i}\" for i in range(clf.coef_.shape[1])]\n",
    "\n",
    "    coefs = clf.coef_.ravel().astype(float)\n",
    "\n",
    "    coef_df = pd.DataFrame({\n",
    "        \"feature\": feat_names,\n",
    "        \"coef\": coefs,\n",
    "        \"OR\": np.exp(coefs)\n",
    "    })\n",
    "\n",
    "    # Make it neat for Excel\n",
    "    coef_df[\"coef\"] = coef_df[\"coef\"].round(6)\n",
    "    coef_df[\"OR\"] = coef_df[\"OR\"].round(6)\n",
    "\n",
    "    # Sort by absolute coefficient magnitude\n",
    "    coef_df = coef_df.sort_values(\"coef\", key=lambda s: np.abs(s), ascending=False).reset_index(drop=True)\n",
    "    return coef_df\n",
    "\n",
    "def save_outcome_package(outcome_name, results_df, best_overall, best_linear, roc_png, roc_points, coef_df, model_path):\n",
    "    \"\"\"\n",
    "    One clean Excel export per outcome, with separate sheets.\n",
    "    \"\"\"\n",
    "    out_xlsx = os.path.join(OUT_DIR, f\"{outcome_name}_PHASE2_EXPORT.xlsx\")\n",
    "\n",
    "    with pd.ExcelWriter(out_xlsx, engine=\"openpyxl\") as writer:\n",
    "        results_df.sort_values([\"AUROC\", \"AUPRC\", \"Brier\"], ascending=[False, False, True]) \\\n",
    "                  .to_excel(writer, sheet_name=\"Model_Comparison\", index=False)\n",
    "\n",
    "        summary_df = pd.DataFrame([{\n",
    "            \"Outcome\": outcome_name,\n",
    "            \"Best_Overall_Model\": best_overall,\n",
    "            \"Best_Linear_Model_For_Risk\": best_linear,\n",
    "            \"Best_ROC_Plot\": roc_png,\n",
    "            \"Best_ROC_Points\": roc_points,\n",
    "            \"Best_Model_Pipeline\": model_path\n",
    "        }])\n",
    "        summary_df.to_excel(writer, sheet_name=\"Selected_Model_Summary\", index=False)\n",
    "\n",
    "        coef_df.to_excel(writer, sheet_name=\"Best_Linear_Coefficients\", index=False)\n",
    "\n",
    "    print(f\"[{outcome_name}] Single export saved to: {out_xlsx}\")\n",
    "    return out_xlsx\n",
    "\n",
    "# ---------------------------\n",
    "# Core runner per outcome\n",
    "# ---------------------------\n",
    "def run_phase2_package(df, y_col, predictors, outcome_name, random_state=42):\n",
    "    # Locked predictors\n",
    "    cols = [c for c in predictors if c in df.columns]\n",
    "    X_all = df[cols].copy()\n",
    "\n",
    "    # Outcome is already cleaned earlier, but filter safely\n",
    "    y_num = pd.to_numeric(df[y_col], errors=\"coerce\")\n",
    "    keep = y_num.isin([0, 1])\n",
    "    X = X_all.loc[keep].copy()\n",
    "    y = y_num.loc[keep].astype(int).values\n",
    "\n",
    "    if len(np.unique(y)) != 2:\n",
    "        raise ValueError(f\"[{outcome_name}] Outcome not binary after filtering.\")\n",
    "\n",
    "    cv_outer = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    cv_inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=random_state)\n",
    "\n",
    "    pre_lin  = make_preprocessor(X, dense_for_trees=False)\n",
    "    pre_tree = make_preprocessor(X, dense_for_trees=True)\n",
    "\n",
    "    # Models + searches\n",
    "    pipe_l2 = Pipeline([(\"pre\", pre_lin), (\"clf\", LogisticRegression(solver=\"lbfgs\", max_iter=6000))])\n",
    "    search_l2 = GridSearchCV(pipe_l2, {\"clf__C\": np.logspace(-3, 2, 10)}, scoring=\"roc_auc\", cv=cv_inner, n_jobs=-1)\n",
    "\n",
    "    pipe_en = Pipeline([(\"pre\", pre_lin), (\"clf\", LogisticRegression(solver=\"saga\", penalty=\"elasticnet\", max_iter=9000))])\n",
    "    search_en = GridSearchCV(pipe_en, {\"clf__C\": np.logspace(-3, 2, 8), \"clf__l1_ratio\": [0.1,0.3,0.5,0.7,0.9]},\n",
    "                             scoring=\"roc_auc\", cv=cv_inner, n_jobs=-1)\n",
    "\n",
    "    pipe_rf = Pipeline([(\"pre\", pre_tree),\n",
    "                        (\"clf\", RandomForestClassifier(n_estimators=600, random_state=random_state, class_weight=\"balanced\"))])\n",
    "    search_rf = GridSearchCV(pipe_rf, {\"clf__max_depth\":[None,3,5,8], \"clf__min_samples_leaf\":[1,3,5], \"clf__max_features\":[\"sqrt\",\"log2\",None]},\n",
    "                             scoring=\"roc_auc\", cv=cv_inner, n_jobs=-1)\n",
    "\n",
    "    pipe_gb = Pipeline([(\"pre\", pre_tree), (\"clf\", GradientBoostingClassifier(random_state=random_state))])\n",
    "    search_gb = GridSearchCV(pipe_gb, {\"clf__n_estimators\":[200,400], \"clf__learning_rate\":[0.03,0.05,0.1],\n",
    "                                       \"clf__max_depth\":[2,3], \"clf__subsample\":[0.8,1.0]},\n",
    "                             scoring=\"roc_auc\", cv=cv_inner, n_jobs=-1)\n",
    "\n",
    "    model_pack = {\n",
    "        \"Logistic_L2\": search_l2,\n",
    "        \"ElasticNet_Logit\": search_en,\n",
    "        \"RandomForest\": search_rf,\n",
    "        \"GradientBoosting\": search_gb\n",
    "    }\n",
    "\n",
    "    # OOF metrics\n",
    "    results = []\n",
    "    oof_probs = {}\n",
    "\n",
    "    for mname, search in model_pack.items():\n",
    "        probs = cross_val_predict(search, X, y, cv=cv_outer, method=\"predict_proba\", n_jobs=-1)[:, 1]\n",
    "        oof_probs[mname] = probs\n",
    "        results.append(compute_metrics(y, probs, outcome_name, mname))\n",
    "        print(f\"[{outcome_name}] done: {mname} | AUROC={results[-1]['AUROC']:.3f}\")\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Best overall model for ROC plot + saved pipeline\n",
    "    best_overall = pick_best_overall(results_df)\n",
    "    best_probs = oof_probs[best_overall]\n",
    "\n",
    "    roc_png = os.path.join(PLOTS_DIR, f\"{outcome_name}_BEST_ROC.png\")\n",
    "    roc_pts = os.path.join(OUT_DIR, f\"{outcome_name}_BEST_ROC_points.xlsx\")\n",
    "\n",
    "    plot_best_roc(y, best_probs, outcome_name, best_overall, roc_png, roc_pts)\n",
    "\n",
    "    # Fit best overall on full data (save pipeline)\n",
    "    best_search = model_pack[best_overall]\n",
    "    best_search.fit(X, y)\n",
    "    model_path = os.path.join(OUT_DIR, f\"{outcome_name}_BEST_model_pipeline.joblib\")\n",
    "    joblib.dump(best_search, model_path)\n",
    "\n",
    "    # Best linear model for risk scoring (coefficients)\n",
    "    best_linear = pick_best_linear(results_df)\n",
    "    if best_linear is None:\n",
    "        raise ValueError(f\"[{outcome_name}] No linear model available for coefficient export.\")\n",
    "\n",
    "    linear_search = model_pack[best_linear]\n",
    "    linear_search.fit(X, y)\n",
    "    coef_df = extract_linear_coefficients(linear_search)\n",
    "\n",
    "    # Single clean export per outcome\n",
    "    out_xlsx = save_outcome_package(\n",
    "        outcome_name=outcome_name,\n",
    "        results_df=results_df,\n",
    "        best_overall=best_overall,\n",
    "        best_linear=best_linear,\n",
    "        roc_png=roc_png,\n",
    "        roc_points=roc_pts,\n",
    "        coef_df=coef_df,\n",
    "        model_path=model_path\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"outcome\": outcome_name,\n",
    "        \"export_xlsx\": out_xlsx,\n",
    "        \"best_overall\": best_overall,\n",
    "        \"best_linear\": best_linear,\n",
    "        \"roc_png\": roc_png,\n",
    "        \"model_joblib\": model_path\n",
    "    }\n",
    "\n",
    "# ============================================================\n",
    "# RUN (both outcomes)\n",
    "# ============================================================\n",
    "# Assumes these already exist from your locked blocks:\n",
    "#   hosp_df, adr_model_df\n",
    "#   hosp_predictors, adr_predictors\n",
    "\n",
    "hosp_pack = run_phase2_package(\n",
    "    df=hosp_df,\n",
    "    y_col=\"hospitalization_flag\",\n",
    "    predictors=hosp_predictors,\n",
    "    outcome_name=\"Hospitalization\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "adr_pack = run_phase2_package(\n",
    "    df=adr_model_df,\n",
    "    y_col=\"severe_adr_flag\",\n",
    "    predictors=adr_predictors,\n",
    "    outcome_name=\"Severe_ADR\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nDONE\")\n",
    "print(\"Hospitalization package:\", hosp_pack)\n",
    "print(\"Severe ADR package:\", adr_pack)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5b97dfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from textwrap import shorten\n",
    "\n",
    "def plot_top_features_clean(\n",
    "    res_df: pd.DataFrame,\n",
    "    outcome_name: str,\n",
    "    top_k: int,\n",
    "    save_plot: str = None,\n",
    "    max_feat_len: int = 35\n",
    "):\n",
    "    \"\"\"\n",
    "    res_df must contain:\n",
    "      - feature\n",
    "      - neg_log10_q\n",
    "      - test\n",
    "      - effect_size\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure proper order and reset index for plotting\n",
    "    plot_df = res_df.sort_values(\"neg_log10_q\", ascending=False).head(top_k).reset_index(drop=True)\n",
    "\n",
    "    # Optional: shorten long feature names (keeps plot readable)\n",
    "    plot_df[\"feature_short\"] = plot_df[\"feature\"].apply(\n",
    "        lambda s: shorten(str(s), width=max_feat_len, placeholder=\"...\")\n",
    "    )\n",
    "\n",
    "    y_pos = np.arange(len(plot_df))\n",
    "    x_vals = plot_df[\"neg_log10_q\"].values\n",
    "\n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.barh(y_pos, x_vals)\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(plot_df[\"feature_short\"])\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    ax.set_xlabel(\"-log10(FDR q-value)\")\n",
    "    ax.set_title(f\"Top {top_k} Features - {outcome_name}\")\n",
    "\n",
    "    # Add padding so labels never spill outside plot area\n",
    "    x_max = float(np.nanmax(x_vals)) if len(x_vals) else 1.0\n",
    "    ax.set_xlim(0, x_max * 1.18 + 0.02)\n",
    "\n",
    "    # Decide inside vs outside placement\n",
    "    # If bar is \"long\", place text inside; else outside\n",
    "    inside_cutoff = 0.65 * x_max if x_max > 0 else 0.0\n",
    "\n",
    "    for i in range(len(plot_df)):\n",
    "        x = plot_df.loc[i, \"neg_log10_q\"]\n",
    "        label = f\"{plot_df.loc[i, 'test']} | ES={plot_df.loc[i, 'effect_size']:.2f}\"\n",
    "\n",
    "        if x >= inside_cutoff:\n",
    "            # Put inside the bar, near the end\n",
    "            ax.text(\n",
    "                x - 0.02 * x_max, i, label,\n",
    "                va=\"center\", ha=\"right\",\n",
    "                fontsize=10, color=\"black\"\n",
    "            )\n",
    "        else:\n",
    "            # Put outside the bar\n",
    "            ax.text(\n",
    "                x + 0.02 * x_max, i, label,\n",
    "                va=\"center\", ha=\"left\",\n",
    "                fontsize=10, color=\"black\"\n",
    "            )\n",
    "\n",
    "    # Improve margins so y labels don't clip\n",
    "    plt.subplots_adjust(left=0.28)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_plot:\n",
    "        plt.savefig(save_plot, dpi=220)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41088906",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_features_clean(\n",
    "    res_df=adr_top,\n",
    "    outcome_name=\"Severe_ADR\",\n",
    "    top_k=15,\n",
    "    save_plot=r\"C:\\Users\\HP\\OneDrive\\Desktop\\Phase 2\\Binary Models\\Plots\\Top15_Severe_ADR_features.png\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d78dcb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_features_clean(\n",
    "    res_df=hosp_top,\n",
    "    outcome_name=\"Hospitalization\",\n",
    "    top_k=15,\n",
    "    save_plot=r\"C:\\Users\\HP\\OneDrive\\Desktop\\Phase 2\\Binary Models\\Plots\\Top15_Hospitalization_features.png\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27deeae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_24692\\3574143870.py:24: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  raw = df[col].astype(str).str.lower().str.strip().replace(yes_no_map)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_24692\\3574143870.py:193: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  uni_df.to_excel(out_path, index=False)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_24692\\3574143870.py:24: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  raw = df[col].astype(str).str.lower().str.strip().replace(yes_no_map)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Univariate logistic] Hospitalization results saved to:\n",
      "  C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\new_data\\binary_models\\univariate_logistic_Hospitalization_with_OR.xlsx\n",
      "[Univariate logistic] Severe_ADR results saved to:\n",
      "  C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\new_data\\binary_models\\univariate_logistic_SevereADR_with_OR.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_24692\\3574143870.py:193: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  uni_df.to_excel(out_path, index=False)\n"
     ]
    }
   ],
   "source": [
    "# Hospitalization\n",
    "hosp_uni_path = os.path.join(BIN_OUT_DIR, \"univariate_logistic_Hospitalization_with_OR.xlsx\")\n",
    "hosp_uni_results = run_univariate_logistic(\n",
    "    df=hosp_df,\n",
    "    y_col=\"hospitalization_flag\",\n",
    "    predictors=hosp_predictors,\n",
    "    outcome_name=\"Hospitalization\",\n",
    "    out_path=hosp_uni_path\n",
    ")\n",
    "\n",
    "# Severe ADR\n",
    "adr_uni_path = os.path.join(BIN_OUT_DIR, \"univariate_logistic_SevereADR_with_OR.xlsx\")\n",
    "adr_uni_results = run_univariate_logistic(\n",
    "    df=adr_model_df,\n",
    "    y_col=\"severe_adr_flag\",\n",
    "    predictors=adr_predictors,\n",
    "    outcome_name=\"Severe_ADR\",\n",
    "    out_path=adr_uni_path\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dab3de84",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from adjustText import adjust_text\n",
    "    HAS_ADJUSTTEXT = True\n",
    "except Exception:\n",
    "    HAS_ADJUSTTEXT = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "435fe9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "Q_THRESH = 0.05\n",
    "MAX_LABELS = 12\n",
    "EXCLUDE_REGEX = r\"(Intercept|_nan\\b|_RARE\\b)\"\n",
    "\n",
    "def pretty_label(s: str) -> str:\n",
    "    s = str(s).replace(\"_\", \" \")\n",
    "    s = \" \".join(s.split())\n",
    "    s = s.replace(\"white blood cells range\", \"WBC range\")\n",
    "    s = s.replace(\"red blood cells range\", \"RBC range\")\n",
    "    s = s.replace(\"hemoglobin range\", \"Hb range\")\n",
    "    s = s.replace(\"platelet count range\", \"Platelets range\")\n",
    "    s = s.replace(\"neutrophils percent range\", \"Neutrophils range\")\n",
    "    return s\n",
    "\n",
    "def plot_clean_volcano_from_uni(\n",
    "    df,\n",
    "    outcome_name,\n",
    "    plot_dir,\n",
    "    q_col=None,                 # e.g., \"q_value_fdr_bh\" or \"q_value_fdr_bh\" (ADR)\n",
    "    p_col=\"p_value\",            # raw p\n",
    "    effect_col=\"coef\",          # signed effect\n",
    "    feature_col=\"Feature\",\n",
    "    extra_exclude_regex=None,\n",
    "    winsor_q=(0.02, 0.98),\n",
    "    max_labels=MAX_LABELS\n",
    "):\n",
    "    os.makedirs(plot_dir, exist_ok=True)\n",
    "    df = df.copy()\n",
    "\n",
    "    # Filter by outcome if the column exists\n",
    "    if \"Outcome\" in df.columns:\n",
    "        df = df[df[\"Outcome\"] == outcome_name].copy()\n",
    "\n",
    "    # Drop junk features\n",
    "    pat = EXCLUDE_REGEX\n",
    "    if extra_exclude_regex:\n",
    "        pat = f\"({pat}|{extra_exclude_regex})\"\n",
    "    df = df[~df[feature_col].astype(str).str.contains(pat, case=False, na=False)].copy()\n",
    "\n",
    "    # Ensure numeric\n",
    "    df[\"effect\"] = pd.to_numeric(df[effect_col], errors=\"coerce\")\n",
    "    df[\"pval\"]   = pd.to_numeric(df[p_col], errors=\"coerce\")\n",
    "\n",
    "    # Compute q-values if missing\n",
    "    if q_col is None or q_col not in df.columns:\n",
    "        # BH-FDR correction\n",
    "        p = df[\"pval\"].values\n",
    "        mask = np.isfinite(p)\n",
    "        q = np.full_like(p, np.nan, dtype=float)\n",
    "\n",
    "        if mask.sum() > 0:\n",
    "            p_valid = p[mask]\n",
    "            order = np.argsort(p_valid)\n",
    "            ranked = p_valid[order]\n",
    "            m = len(ranked)\n",
    "            bh = ranked * m / (np.arange(1, m + 1))\n",
    "            bh = np.minimum.accumulate(bh[::-1])[::-1]\n",
    "            bh = np.clip(bh, 0, 1)\n",
    "\n",
    "            q_valid = np.empty_like(bh)\n",
    "            q_valid[order] = bh\n",
    "            q[mask] = q_valid\n",
    "\n",
    "        df[\"qval\"] = q\n",
    "        q_used = \"computed_BH_FDR\"\n",
    "    else:\n",
    "        df[\"qval\"] = pd.to_numeric(df[q_col], errors=\"coerce\")\n",
    "        q_used = q_col\n",
    "\n",
    "    df = df.dropna(subset=[\"effect\", \"qval\"]).copy()\n",
    "    if df.empty:\n",
    "        print(f\"[{outcome_name}] No usable rows after cleaning.\")\n",
    "        return\n",
    "\n",
    "    df[\"neglog10_q\"] = -np.log10(df[\"qval\"].clip(lower=1e-300))\n",
    "    df[\"_abs_eff\"] = df[\"effect\"].abs()\n",
    "\n",
    "    sig = df[\"qval\"] < Q_THRESH\n",
    "    up = sig & (df[\"effect\"] > 0)\n",
    "    down = sig & (df[\"effect\"] < 0)\n",
    "    nonsig = ~sig\n",
    "\n",
    "    # Label selection: significant first, then large effect\n",
    "    sig_pool = df[sig].sort_values([\"qval\", \"_abs_eff\"], ascending=[True, False])\n",
    "    if len(sig_pool) >= max_labels:\n",
    "        label_df = sig_pool.head(max_labels)\n",
    "    else:\n",
    "        fill = df.sort_values([\"_abs_eff\", \"qval\"], ascending=[False, True]).head(max_labels)\n",
    "        label_df = pd.concat([sig_pool, fill]).drop_duplicates().head(max_labels)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 7))\n",
    "\n",
    "    plt.scatter(df.loc[nonsig, \"effect\"], df.loc[nonsig, \"neglog10_q\"],\n",
    "                s=28, alpha=0.25, label=\"Not significant\")\n",
    "\n",
    "    plt.scatter(df.loc[up, \"effect\"], df.loc[up, \"neglog10_q\"],\n",
    "                s=45, alpha=0.9, label=f\"q<{Q_THRESH}, coef>0\")\n",
    "\n",
    "    plt.scatter(df.loc[down, \"effect\"], df.loc[down, \"neglog10_q\"],\n",
    "                s=45, alpha=0.9, label=f\"q<{Q_THRESH}, coef<0\")\n",
    "\n",
    "    plt.axhline(-np.log10(Q_THRESH), linestyle=\"--\", linewidth=1)\n",
    "    plt.axvline(0.0, linestyle=\"--\", linewidth=1)\n",
    "\n",
    "    # Winsorized x limits (prevents one outlier from destroying plot)\n",
    "    x = df[\"effect\"].values\n",
    "    if len(x) > 10:\n",
    "        lo, hi = np.quantile(x, winsor_q)\n",
    "        max_abs = max(abs(lo), abs(hi)) * 1.35\n",
    "    else:\n",
    "        max_abs = max(abs(x.min()), abs(x.max())) * 1.35\n",
    "    max_abs = max(max_abs, 0.1)\n",
    "    plt.xlim(-max_abs, max_abs)\n",
    "\n",
    "    plt.xlabel(\"Effect size (signed coef)\")\n",
    "    plt.ylabel(f\"-log10(q-value) [{q_used}]\")\n",
    "    plt.title(f\"Volcano plot â€“ {outcome_name}\")\n",
    "    plt.legend(loc=\"upper right\", fontsize=8, frameon=False)\n",
    "\n",
    "    texts = []\n",
    "    for _, row in label_df.iterrows():\n",
    "        texts.append(\n",
    "            plt.text(row[\"effect\"], row[\"neglog10_q\"], pretty_label(row[feature_col]), fontsize=9)\n",
    "        )\n",
    "\n",
    "    if HAS_ADJUSTTEXT and texts:\n",
    "        adjust_text(\n",
    "            texts,\n",
    "            expand_points=(1.2, 1.4),\n",
    "            expand_text=(1.2, 1.4),\n",
    "            arrowprops=dict(arrowstyle=\"-\", lw=0.8),\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    out_png = os.path.join(plot_dir, f\"univariate_volcano_{outcome_name}_clean.png\")\n",
    "    plt.savefig(out_png, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Export labels\n",
    "    out_xlsx = os.path.join(plot_dir, f\"univariate_volcano_{outcome_name}_labels.xlsx\")\n",
    "    label_export = label_df[[feature_col, \"effect\", \"qval\", \"neglog10_q\", \"pval\"]].copy()\n",
    "    label_export.rename(columns={feature_col: \"Feature\"}, inplace=True)\n",
    "    label_export.to_excel(out_xlsx, index=False)\n",
    "\n",
    "    print(\"Saved:\", out_png)\n",
    "    print(\"Labels:\", out_xlsx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62e12d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_24692\\3459458369.py:43: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df = df[~df[feature_col].astype(str).str.contains(pat, case=False, na=False)].copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\HP\\OneDrive\\Desktop\\Phase 2\\univariate_volcano_Severe_ADR_clean.png\n",
      "Labels: C:\\Users\\HP\\OneDrive\\Desktop\\Phase 2\\univariate_volcano_Severe_ADR_labels.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_24692\\3459458369.py:149: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  label_export.to_excel(out_xlsx, index=False)\n"
     ]
    }
   ],
   "source": [
    "plot_clean_volcano_from_uni(\n",
    "    df=adr_uni_results,\n",
    "    outcome_name=\"Severe_ADR\",  # must match your Outcome values\n",
    "    plot_dir=r\"C:\\Users\\HP\\OneDrive\\Desktop\\Phase 2\",\n",
    "    q_col=\"q_value_fdr_bh\",\n",
    "    p_col=\"p_value\",\n",
    "    effect_col=\"coef\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78df0b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Severe_ADR']\n",
      "['Hospitalization']\n"
     ]
    }
   ],
   "source": [
    "print(adr_uni_results[\"Outcome\"].unique())\n",
    "print(hosp_uni_results[\"Outcome\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5929b165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Hospitalization] No usable rows after cleaning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_24692\\3459458369.py:43: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df = df[~df[feature_col].astype(str).str.contains(pat, case=False, na=False)].copy()\n"
     ]
    }
   ],
   "source": [
    "plot_clean_volcano_from_uni(\n",
    "    df=hosp_uni_results,\n",
    "    outcome_name=\"Hospitalization\",  # must match your Outcome values\n",
    "    plot_dir=r\"C:\\Users\\HP\\OneDrive\\Desktop\\Phase 2\",\n",
    "    q_col=None,      # forces computing BH-FDR\n",
    "    p_col=\"p_value\",\n",
    "    effect_col=\"coef\",\n",
    "    extra_exclude_regex=r\"(hospitalization_count|valid_hospitalization_count|\\bcount\\b|\\bn_\\b)\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c138bd63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
